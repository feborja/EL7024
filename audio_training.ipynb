{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de audio con corrupciones\n",
    "Hecho por:\n",
    "* Ammi Beltrán\n",
    "* Fernanda Borja\n",
    "* Luciano Vidal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirección del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"D:\\\\OneDrive\\\\OneDrive - Universidad de Chile\\\\Semestre X\\\\Teoria de la informacion\\\\proyecto\\\\UrbanSound8K\\\\UrbanSound8K\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Locals\n",
    "import audio.audio_corrupts as corrupt\n",
    "import audio.audio_model as audiotrain\n",
    "import audio.audio_data as dataudio\n",
    "# Torch\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\audio\\fold5\\100032-3-0-0.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-117.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-121.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-126.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-137.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     relative_path  classID\n",
       "0    \\audio\\fold5\\100032-3-0-0.wav        3\n",
       "1  \\audio\\fold5\\100263-2-0-117.wav        2\n",
       "2  \\audio\\fold5\\100263-2-0-121.wav        2\n",
       "3  \\audio\\fold5\\100263-2-0-126.wav        2\n",
       "4  \\audio\\fold5\\100263-2-0-137.wav        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.path.join(DATA, \"metadata\", \"UrbanSound8K.csv\")\n",
    "df = pd.read_csv(file)\n",
    "df['relative_path'] = '\\\\audio' + '\\\\fold' + df['fold'].astype(str) + '\\\\' + df['slice_file_name'].astype(str)\n",
    "df = df[['relative_path', 'classID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8732"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_items = len(df)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train, val = train_test_split(df, test_size=0.2,random_state=420)\n",
    "train, val = train.reset_index(drop = True), val.reset_index(drop = True) \n",
    "# generator1 = torch.Generator().manual_seed(420)\n",
    "# train, val = random_split(df, [num_train, num_val], generator=generator1)\n",
    "# print(val)\n",
    "train_ds = dataudio.SoundDS(train, DATA, transform = True)\n",
    "val_ds = dataudio.SoundDS(val, DATA, transform = False)\n",
    "# print(len(train_ds))\n",
    "# print(val_ds[1])\n",
    "#\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=250, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=250, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# myds = dataudio.SoundDS(df, DATA)\n",
    "\n",
    "# # Random split of 80:20 between training and validation\n",
    "# num_items = len(myds)\n",
    "# num_train = round(num_items * 0.8)\n",
    "# num_val = num_items - num_train\n",
    "# generator1 = torch.Generator().manual_seed(420)\n",
    "# train_ds, val_ds = random_split(myds, [num_train, num_val], generator=generator1)\n",
    "# # Create training and validation data loaders\n",
    "# train_dl = torch.utils.data.DataLoader(train_ds, batch_size=250, shuffle=True)\n",
    "# val_dl = torch.utils.data.DataLoader(val_ds, batch_size=250, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch nro 1/100\n",
      "Iter: 1/28, Loss:2.303687572479248\n",
      "Iter: 2/28, Loss:2.2573790550231934\n",
      "Iter: 3/28, Loss:2.2285776138305664\n",
      "Iter: 4/28, Loss:2.2107887268066406\n",
      "Iter: 5/28, Loss:2.1722755432128906\n",
      "Iter: 6/28, Loss:2.184400796890259\n",
      "Iter: 7/28, Loss:2.1325724124908447\n",
      "Iter: 8/28, Loss:2.1007535457611084\n",
      "Iter: 9/28, Loss:2.0792980194091797\n",
      "Iter: 10/28, Loss:2.0877773761749268\n",
      "Iter: 11/28, Loss:2.0379438400268555\n",
      "Iter: 12/28, Loss:2.0695457458496094\n",
      "Iter: 13/28, Loss:2.0393948554992676\n",
      "Iter: 14/28, Loss:2.0206034183502197\n",
      "Iter: 15/28, Loss:1.9525399208068848\n",
      "Iter: 16/28, Loss:2.0336592197418213\n",
      "Iter: 17/28, Loss:1.9513278007507324\n",
      "Iter: 18/28, Loss:1.9790844917297363\n",
      "Iter: 19/28, Loss:1.958447813987732\n",
      "Iter: 20/28, Loss:1.9477356672286987\n",
      "Iter: 21/28, Loss:1.933546781539917\n",
      "Iter: 22/28, Loss:1.9193873405456543\n",
      "Iter: 23/28, Loss:1.9255808591842651\n",
      "Iter: 24/28, Loss:1.8758074045181274\n",
      "Iter: 25/28, Loss:1.872607707977295\n",
      "Iter: 26/28, Loss:1.9030793905258179\n",
      "Iter: 27/28, Loss:1.89034104347229\n",
      "Iter: 28/28, Loss:1.91181218624115\n",
      "Epoch 1/100: Train loss = 2.034998655319214, Val loss = 1.8882958889007568, Train acc = 0.2817465998568361, Val acc = 0.36290784201488263\n",
      "Better params found in epoch = 1, saved params\n",
      "Epoch nro 2/100\n",
      "Iter: 1/28, Loss:1.813620686531067\n",
      "Iter: 2/28, Loss:1.8847315311431885\n",
      "Iter: 3/28, Loss:1.9306906461715698\n",
      "Iter: 4/28, Loss:1.8085474967956543\n",
      "Iter: 5/28, Loss:1.8200517892837524\n",
      "Iter: 6/28, Loss:1.9020284414291382\n",
      "Iter: 7/28, Loss:1.8657867908477783\n",
      "Iter: 8/28, Loss:1.8197749853134155\n",
      "Iter: 9/28, Loss:1.7641961574554443\n",
      "Iter: 10/28, Loss:1.750291347503662\n",
      "Iter: 11/28, Loss:1.766903281211853\n",
      "Iter: 12/28, Loss:1.7300070524215698\n",
      "Iter: 13/28, Loss:1.7723256349563599\n",
      "Iter: 14/28, Loss:1.8049273490905762\n",
      "Iter: 15/28, Loss:1.758991003036499\n",
      "Iter: 16/28, Loss:1.707965612411499\n",
      "Iter: 17/28, Loss:1.768717646598816\n",
      "Iter: 18/28, Loss:1.7415353059768677\n",
      "Iter: 19/28, Loss:1.671775460243225\n",
      "Iter: 20/28, Loss:1.7102937698364258\n",
      "Iter: 21/28, Loss:1.638685941696167\n",
      "Iter: 22/28, Loss:1.7693113088607788\n",
      "Iter: 23/28, Loss:1.7328448295593262\n",
      "Iter: 24/28, Loss:1.734761118888855\n",
      "Iter: 25/28, Loss:1.6421021223068237\n",
      "Iter: 26/28, Loss:1.6415008306503296\n",
      "Iter: 27/28, Loss:1.6234896183013916\n",
      "Iter: 28/28, Loss:1.747765302658081\n",
      "Epoch 2/100: Train loss = 1.7615580558776855, Val loss = 1.6965895891189575, Train acc = 0.4094488188976378, Val acc = 0.45220377790497995\n",
      "Better params found in epoch = 2, saved params\n",
      "Epoch nro 3/100\n",
      "Iter: 1/28, Loss:1.6698353290557861\n",
      "Iter: 2/28, Loss:1.6853774785995483\n",
      "Iter: 3/28, Loss:1.6109732389450073\n",
      "Iter: 4/28, Loss:1.6554739475250244\n",
      "Iter: 5/28, Loss:1.5969005823135376\n",
      "Iter: 6/28, Loss:1.5706393718719482\n",
      "Iter: 7/28, Loss:1.6541682481765747\n",
      "Iter: 8/28, Loss:1.6960452795028687\n",
      "Iter: 9/28, Loss:1.650307536125183\n",
      "Iter: 10/28, Loss:1.551123857498169\n",
      "Iter: 11/28, Loss:1.7034043073654175\n",
      "Iter: 12/28, Loss:1.6177916526794434\n",
      "Iter: 13/28, Loss:1.5642799139022827\n",
      "Iter: 14/28, Loss:1.6064082384109497\n",
      "Iter: 15/28, Loss:1.4894440174102783\n",
      "Iter: 16/28, Loss:1.5366393327713013\n",
      "Iter: 17/28, Loss:1.5906087160110474\n",
      "Iter: 18/28, Loss:1.5767320394515991\n",
      "Iter: 19/28, Loss:1.5530201196670532\n",
      "Iter: 20/28, Loss:1.5971269607543945\n",
      "Iter: 21/28, Loss:1.6021909713745117\n",
      "Iter: 22/28, Loss:1.4950129985809326\n",
      "Iter: 23/28, Loss:1.5153272151947021\n",
      "Iter: 24/28, Loss:1.5335545539855957\n",
      "Iter: 25/28, Loss:1.5084640979766846\n",
      "Iter: 26/28, Loss:1.6050381660461426\n",
      "Iter: 27/28, Loss:1.5266858339309692\n",
      "Iter: 28/28, Loss:1.470312476158142\n",
      "Epoch 3/100: Train loss = 1.5868891477584839, Val loss = 1.5323243141174316, Train acc = 0.4722977809591983, Val acc = 0.48483113909559244\n",
      "Better params found in epoch = 3, saved params\n",
      "Epoch nro 4/100\n",
      "Iter: 1/28, Loss:1.4087966680526733\n",
      "Iter: 2/28, Loss:1.4927164316177368\n",
      "Iter: 3/28, Loss:1.5237945318222046\n",
      "Iter: 4/28, Loss:1.5171153545379639\n",
      "Iter: 5/28, Loss:1.4387725591659546\n",
      "Iter: 6/28, Loss:1.4352518320083618\n",
      "Iter: 7/28, Loss:1.4487485885620117\n",
      "Iter: 8/28, Loss:1.4922140836715698\n",
      "Iter: 9/28, Loss:1.4313855171203613\n",
      "Iter: 10/28, Loss:1.4657769203186035\n",
      "Iter: 11/28, Loss:1.5162473917007446\n",
      "Iter: 12/28, Loss:1.5094712972640991\n",
      "Iter: 13/28, Loss:1.4918606281280518\n",
      "Iter: 14/28, Loss:1.4994279146194458\n",
      "Iter: 15/28, Loss:1.4003740549087524\n",
      "Iter: 16/28, Loss:1.4423489570617676\n",
      "Iter: 17/28, Loss:1.485257863998413\n",
      "Iter: 18/28, Loss:1.4619054794311523\n",
      "Iter: 19/28, Loss:1.439853549003601\n",
      "Iter: 20/28, Loss:1.4610532522201538\n",
      "Iter: 21/28, Loss:1.4315215349197388\n",
      "Iter: 22/28, Loss:1.4487336874008179\n",
      "Iter: 23/28, Loss:1.3482444286346436\n",
      "Iter: 24/28, Loss:1.4097346067428589\n",
      "Iter: 25/28, Loss:1.4447590112686157\n",
      "Iter: 26/28, Loss:1.4658071994781494\n",
      "Iter: 27/28, Loss:1.3547197580337524\n",
      "Iter: 28/28, Loss:1.399054765701294\n",
      "Epoch 4/100: Train loss = 1.452319622039795, Val loss = 1.4877657890319824, Train acc = 0.5195418754473873, Val acc = 0.5157412707498569\n",
      "Better params found in epoch = 4, saved params\n",
      "Epoch nro 5/100\n",
      "Iter: 1/28, Loss:1.4059799909591675\n",
      "Iter: 2/28, Loss:1.5544759035110474\n",
      "Iter: 3/28, Loss:1.400283694267273\n",
      "Iter: 4/28, Loss:1.3424948453903198\n",
      "Iter: 5/28, Loss:1.4530811309814453\n",
      "Iter: 6/28, Loss:1.3990564346313477\n",
      "Iter: 7/28, Loss:1.3807542324066162\n",
      "Iter: 8/28, Loss:1.393664836883545\n",
      "Iter: 9/28, Loss:1.411050796508789\n",
      "Iter: 10/28, Loss:1.445512294769287\n",
      "Iter: 11/28, Loss:1.2725121974945068\n",
      "Iter: 12/28, Loss:1.281065583229065\n",
      "Iter: 13/28, Loss:1.3296440839767456\n",
      "Iter: 14/28, Loss:1.3492625951766968\n",
      "Iter: 15/28, Loss:1.3664906024932861\n",
      "Iter: 16/28, Loss:1.3705134391784668\n",
      "Iter: 17/28, Loss:1.4117295742034912\n",
      "Iter: 18/28, Loss:1.3710660934448242\n",
      "Iter: 19/28, Loss:1.3381377458572388\n",
      "Iter: 20/28, Loss:1.3671847581863403\n",
      "Iter: 21/28, Loss:1.3563594818115234\n",
      "Iter: 22/28, Loss:1.3892998695373535\n",
      "Iter: 23/28, Loss:1.3407974243164062\n",
      "Iter: 24/28, Loss:1.265207052230835\n",
      "Iter: 25/28, Loss:1.2597062587738037\n",
      "Iter: 26/28, Loss:1.3069145679473877\n",
      "Iter: 27/28, Loss:1.312434434890747\n",
      "Iter: 28/28, Loss:1.290482997894287\n",
      "Epoch 5/100: Train loss = 1.363041639328003, Val loss = 1.3848594427108765, Train acc = 0.549176807444524, Val acc = 0.5580995993131082\n",
      "Better params found in epoch = 5, saved params\n",
      "Epoch nro 6/100\n",
      "Iter: 1/28, Loss:1.2428231239318848\n",
      "Iter: 2/28, Loss:1.3800485134124756\n",
      "Iter: 3/28, Loss:1.3339083194732666\n",
      "Iter: 4/28, Loss:1.2698609828948975\n",
      "Iter: 5/28, Loss:1.2727996110916138\n",
      "Iter: 6/28, Loss:1.303308367729187\n",
      "Iter: 7/28, Loss:1.313867211341858\n",
      "Iter: 8/28, Loss:1.3114821910858154\n",
      "Iter: 9/28, Loss:1.2912019491195679\n",
      "Iter: 10/28, Loss:1.2253756523132324\n",
      "Iter: 11/28, Loss:1.311913013458252\n",
      "Iter: 12/28, Loss:1.328879952430725\n",
      "Iter: 13/28, Loss:1.2356199026107788\n",
      "Iter: 14/28, Loss:1.3129385709762573\n",
      "Iter: 15/28, Loss:1.270808219909668\n",
      "Iter: 16/28, Loss:1.2456657886505127\n",
      "Iter: 17/28, Loss:1.2805030345916748\n",
      "Iter: 18/28, Loss:1.3103907108306885\n",
      "Iter: 19/28, Loss:1.1889654397964478\n",
      "Iter: 20/28, Loss:1.1959936618804932\n",
      "Iter: 21/28, Loss:1.2122563123703003\n",
      "Iter: 22/28, Loss:1.2928591966629028\n",
      "Iter: 23/28, Loss:1.272306203842163\n",
      "Iter: 24/28, Loss:1.4010940790176392\n",
      "Iter: 25/28, Loss:1.2441715002059937\n",
      "Iter: 26/28, Loss:1.2599674463272095\n",
      "Iter: 27/28, Loss:1.2169651985168457\n",
      "Iter: 28/28, Loss:1.2609000205993652\n",
      "Epoch 6/100: Train loss = 1.2781026363372803, Val loss = 1.3219190835952759, Train acc = 0.5748031496062992, Val acc = 0.5638236977676016\n",
      "Better params found in epoch = 6, saved params\n",
      "Epoch nro 7/100\n",
      "Iter: 1/28, Loss:1.2719895839691162\n",
      "Iter: 2/28, Loss:1.1714223623275757\n",
      "Iter: 3/28, Loss:1.205419898033142\n",
      "Iter: 4/28, Loss:1.2485828399658203\n",
      "Iter: 5/28, Loss:1.2421033382415771\n",
      "Iter: 6/28, Loss:1.1952227354049683\n",
      "Iter: 7/28, Loss:1.167076826095581\n",
      "Iter: 8/28, Loss:1.2465126514434814\n",
      "Iter: 9/28, Loss:1.1931160688400269\n",
      "Iter: 10/28, Loss:1.261527180671692\n",
      "Iter: 11/28, Loss:1.186678171157837\n",
      "Iter: 12/28, Loss:1.1896415948867798\n",
      "Iter: 13/28, Loss:1.1848704814910889\n",
      "Iter: 14/28, Loss:1.2092252969741821\n",
      "Iter: 15/28, Loss:1.1521552801132202\n",
      "Iter: 16/28, Loss:1.2392117977142334\n",
      "Iter: 17/28, Loss:1.1501407623291016\n",
      "Iter: 18/28, Loss:1.126708984375\n",
      "Iter: 19/28, Loss:1.2008533477783203\n",
      "Iter: 20/28, Loss:1.2006711959838867\n",
      "Iter: 21/28, Loss:1.045809268951416\n",
      "Iter: 22/28, Loss:1.2059365510940552\n",
      "Iter: 23/28, Loss:1.2015615701675415\n",
      "Iter: 24/28, Loss:1.3001431226730347\n",
      "Iter: 25/28, Loss:1.2789664268493652\n",
      "Iter: 26/28, Loss:1.0878863334655762\n",
      "Iter: 27/28, Loss:1.1903905868530273\n",
      "Iter: 28/28, Loss:1.1635786294937134\n",
      "Epoch 7/100: Train loss = 1.1970499753952026, Val loss = 1.2829351425170898, Train acc = 0.6084466714387974, Val acc = 0.5781339439038351\n",
      "Better params found in epoch = 7, saved params\n",
      "Epoch nro 8/100\n",
      "Iter: 1/28, Loss:1.1492223739624023\n",
      "Iter: 2/28, Loss:1.2513154745101929\n",
      "Iter: 3/28, Loss:1.2731553316116333\n",
      "Iter: 4/28, Loss:1.082898497581482\n",
      "Iter: 5/28, Loss:1.1909576654434204\n",
      "Iter: 6/28, Loss:1.1206371784210205\n",
      "Iter: 7/28, Loss:1.1584913730621338\n",
      "Iter: 8/28, Loss:1.182129979133606\n",
      "Iter: 9/28, Loss:1.1076706647872925\n",
      "Iter: 10/28, Loss:1.2211873531341553\n",
      "Iter: 11/28, Loss:1.0725383758544922\n",
      "Iter: 12/28, Loss:1.0902174711227417\n",
      "Iter: 13/28, Loss:1.1747480630874634\n",
      "Iter: 14/28, Loss:1.1517173051834106\n",
      "Iter: 15/28, Loss:1.1565628051757812\n",
      "Iter: 16/28, Loss:1.1139765977859497\n",
      "Iter: 17/28, Loss:1.2055233716964722\n",
      "Iter: 18/28, Loss:1.1706907749176025\n",
      "Iter: 19/28, Loss:1.2431880235671997\n",
      "Iter: 20/28, Loss:1.1205395460128784\n",
      "Iter: 21/28, Loss:1.1275835037231445\n",
      "Iter: 22/28, Loss:1.102417230606079\n",
      "Iter: 23/28, Loss:1.0993773937225342\n",
      "Iter: 24/28, Loss:1.1366941928863525\n",
      "Iter: 25/28, Loss:1.1085388660430908\n",
      "Iter: 26/28, Loss:1.0302785634994507\n",
      "Iter: 27/28, Loss:1.2515090703964233\n",
      "Iter: 28/28, Loss:1.1807788610458374\n",
      "Epoch 8/100: Train loss = 1.1526625156402588, Val loss = 1.1914727687835693, Train acc = 0.6236220472440945, Val acc = 0.6004579278763594\n",
      "Better params found in epoch = 8, saved params\n",
      "Epoch nro 9/100\n",
      "Iter: 1/28, Loss:1.087308645248413\n",
      "Iter: 2/28, Loss:1.1675509214401245\n",
      "Iter: 3/28, Loss:1.135825276374817\n",
      "Iter: 4/28, Loss:1.0944812297821045\n",
      "Iter: 5/28, Loss:1.1544835567474365\n",
      "Iter: 6/28, Loss:1.1297861337661743\n",
      "Iter: 7/28, Loss:1.1730958223342896\n",
      "Iter: 8/28, Loss:1.089292049407959\n",
      "Iter: 9/28, Loss:1.0460892915725708\n",
      "Iter: 10/28, Loss:1.081905722618103\n",
      "Iter: 11/28, Loss:1.0452526807785034\n",
      "Iter: 12/28, Loss:1.0293456315994263\n",
      "Iter: 13/28, Loss:0.9951320290565491\n",
      "Iter: 14/28, Loss:1.119247317314148\n",
      "Iter: 15/28, Loss:1.1780450344085693\n",
      "Iter: 16/28, Loss:1.1129229068756104\n",
      "Iter: 17/28, Loss:1.0657182931900024\n",
      "Iter: 18/28, Loss:1.1396443843841553\n",
      "Iter: 19/28, Loss:1.040283203125\n",
      "Iter: 20/28, Loss:1.0312397480010986\n",
      "Iter: 21/28, Loss:1.1071803569793701\n",
      "Iter: 22/28, Loss:1.0678116083145142\n",
      "Iter: 23/28, Loss:1.0662736892700195\n",
      "Iter: 24/28, Loss:1.0940525531768799\n",
      "Iter: 25/28, Loss:1.0475215911865234\n",
      "Iter: 26/28, Loss:1.083958625793457\n",
      "Iter: 27/28, Loss:1.0045603513717651\n",
      "Iter: 28/28, Loss:1.0890370607376099\n",
      "Epoch 9/100: Train loss = 1.088465929031372, Val loss = 1.1664602756500244, Train acc = 0.6416607015032212, Val acc = 0.6124785346307956\n",
      "Better params found in epoch = 9, saved params\n",
      "Epoch nro 10/100\n",
      "Iter: 1/28, Loss:1.0920631885528564\n",
      "Iter: 2/28, Loss:1.0487496852874756\n",
      "Iter: 3/28, Loss:1.0093870162963867\n",
      "Iter: 4/28, Loss:1.0757708549499512\n",
      "Iter: 5/28, Loss:1.146106481552124\n",
      "Iter: 6/28, Loss:0.9732932448387146\n",
      "Iter: 7/28, Loss:0.9966177344322205\n",
      "Iter: 8/28, Loss:1.047900915145874\n",
      "Iter: 9/28, Loss:1.107564926147461\n",
      "Iter: 10/28, Loss:1.0723137855529785\n",
      "Iter: 11/28, Loss:1.0486277341842651\n",
      "Iter: 12/28, Loss:1.0412980318069458\n",
      "Iter: 13/28, Loss:0.9874064326286316\n",
      "Iter: 14/28, Loss:0.9894881844520569\n",
      "Iter: 15/28, Loss:0.9824181199073792\n",
      "Iter: 16/28, Loss:1.0076045989990234\n",
      "Iter: 17/28, Loss:1.1383341550827026\n",
      "Iter: 18/28, Loss:0.9524847269058228\n",
      "Iter: 19/28, Loss:1.018847942352295\n",
      "Iter: 20/28, Loss:1.0884513854980469\n",
      "Iter: 21/28, Loss:1.0734354257583618\n",
      "Iter: 22/28, Loss:1.1316077709197998\n",
      "Iter: 23/28, Loss:1.0638827085494995\n",
      "Iter: 24/28, Loss:0.9736664295196533\n",
      "Iter: 25/28, Loss:1.1320830583572388\n",
      "Iter: 26/28, Loss:1.0501476526260376\n",
      "Iter: 27/28, Loss:0.9582670331001282\n",
      "Iter: 28/28, Loss:0.9895433187484741\n",
      "Epoch 10/100: Train loss = 1.0427629947662354, Val loss = 1.1739269495010376, Train acc = 0.6632784538296349, Val acc = 0.6176302232398397\n",
      "Epoch nro 11/100\n",
      "Iter: 1/28, Loss:1.1607059240341187\n",
      "Iter: 2/28, Loss:1.005664348602295\n",
      "Iter: 3/28, Loss:0.9731481075286865\n",
      "Iter: 4/28, Loss:1.0130857229232788\n",
      "Iter: 5/28, Loss:0.9554672241210938\n",
      "Iter: 6/28, Loss:0.9185280203819275\n",
      "Iter: 7/28, Loss:1.0079776048660278\n",
      "Iter: 8/28, Loss:1.0109962224960327\n",
      "Iter: 9/28, Loss:1.0001935958862305\n",
      "Iter: 10/28, Loss:0.99642014503479\n",
      "Iter: 11/28, Loss:0.9734521508216858\n",
      "Iter: 12/28, Loss:0.956807017326355\n",
      "Iter: 13/28, Loss:1.0286015272140503\n",
      "Iter: 14/28, Loss:1.0433833599090576\n",
      "Iter: 15/28, Loss:0.9281927943229675\n",
      "Iter: 16/28, Loss:1.0101442337036133\n",
      "Iter: 17/28, Loss:0.9702820777893066\n",
      "Iter: 18/28, Loss:1.0699559450149536\n",
      "Iter: 19/28, Loss:0.9481503367424011\n",
      "Iter: 20/28, Loss:0.9570211172103882\n",
      "Iter: 21/28, Loss:0.9769214391708374\n",
      "Iter: 22/28, Loss:0.8744120001792908\n",
      "Iter: 23/28, Loss:0.9220927953720093\n",
      "Iter: 24/28, Loss:1.0065069198608398\n",
      "Iter: 25/28, Loss:1.0124163627624512\n",
      "Iter: 26/28, Loss:0.9537746906280518\n",
      "Iter: 27/28, Loss:0.984171450138092\n",
      "Iter: 28/28, Loss:1.0279494524002075\n",
      "Epoch 11/100: Train loss = 0.9888008832931519, Val loss = 1.0891714096069336, Train acc = 0.6801717967072298, Val acc = 0.6307956496851745\n",
      "Better params found in epoch = 11, saved params\n",
      "Epoch nro 12/100\n",
      "Iter: 1/28, Loss:0.9396042227745056\n",
      "Iter: 2/28, Loss:0.997072696685791\n",
      "Iter: 3/28, Loss:0.9835112690925598\n",
      "Iter: 4/28, Loss:0.953126847743988\n",
      "Iter: 5/28, Loss:1.0449349880218506\n",
      "Iter: 6/28, Loss:0.9427337050437927\n",
      "Iter: 7/28, Loss:0.9419711232185364\n",
      "Iter: 8/28, Loss:0.9343236088752747\n",
      "Iter: 9/28, Loss:1.0386642217636108\n",
      "Iter: 10/28, Loss:0.964318037033081\n",
      "Iter: 11/28, Loss:0.9543347358703613\n",
      "Iter: 12/28, Loss:1.0092661380767822\n",
      "Iter: 13/28, Loss:0.925009548664093\n",
      "Iter: 14/28, Loss:0.9272977113723755\n",
      "Iter: 15/28, Loss:0.9157314896583557\n",
      "Iter: 16/28, Loss:0.9869346618652344\n",
      "Iter: 17/28, Loss:0.9634574055671692\n",
      "Iter: 18/28, Loss:0.906810998916626\n",
      "Iter: 19/28, Loss:0.9746681451797485\n",
      "Iter: 20/28, Loss:0.9607033729553223\n",
      "Iter: 21/28, Loss:0.9439780116081238\n",
      "Iter: 22/28, Loss:0.8871634006500244\n",
      "Iter: 23/28, Loss:0.9265569448471069\n",
      "Iter: 24/28, Loss:0.9228041172027588\n",
      "Iter: 25/28, Loss:0.9001119136810303\n",
      "Iter: 26/28, Loss:0.9345594644546509\n",
      "Iter: 27/28, Loss:0.9653798341751099\n",
      "Iter: 28/28, Loss:0.9128398895263672\n",
      "Epoch 12/100: Train loss = 0.9520667195320129, Val loss = 1.0715850591659546, Train acc = 0.6901932712956335, Val acc = 0.6342301087578707\n",
      "Better params found in epoch = 12, saved params\n",
      "Epoch nro 13/100\n",
      "Iter: 1/28, Loss:0.952886164188385\n",
      "Iter: 2/28, Loss:0.8506230115890503\n",
      "Iter: 3/28, Loss:0.9296731352806091\n",
      "Iter: 4/28, Loss:0.8916503190994263\n",
      "Iter: 5/28, Loss:0.8694056272506714\n",
      "Iter: 6/28, Loss:0.8823359608650208\n",
      "Iter: 7/28, Loss:0.8925199508666992\n",
      "Iter: 8/28, Loss:0.8556524515151978\n",
      "Iter: 9/28, Loss:0.8449491262435913\n",
      "Iter: 10/28, Loss:0.9739469885826111\n",
      "Iter: 11/28, Loss:0.9279618263244629\n",
      "Iter: 12/28, Loss:0.9325231313705444\n",
      "Iter: 13/28, Loss:0.9120500683784485\n",
      "Iter: 14/28, Loss:0.9160776734352112\n",
      "Iter: 15/28, Loss:0.8634284138679504\n",
      "Iter: 16/28, Loss:0.8417098522186279\n",
      "Iter: 17/28, Loss:0.8719397187232971\n",
      "Iter: 18/28, Loss:0.903821587562561\n",
      "Iter: 19/28, Loss:0.879001259803772\n",
      "Iter: 20/28, Loss:0.9188171625137329\n",
      "Iter: 21/28, Loss:0.8645980358123779\n",
      "Iter: 22/28, Loss:0.8630565404891968\n",
      "Iter: 23/28, Loss:1.054986596107483\n",
      "Iter: 24/28, Loss:0.9315395951271057\n",
      "Iter: 25/28, Loss:0.9694129824638367\n",
      "Iter: 26/28, Loss:0.8031733632087708\n",
      "Iter: 27/28, Loss:0.9278076887130737\n",
      "Iter: 28/28, Loss:0.8815033435821533\n",
      "Epoch 13/100: Train loss = 0.9002519249916077, Val loss = 1.1039512157440186, Train acc = 0.7090909090909091, Val acc = 0.6267887807670292\n",
      "Epoch nro 14/100\n",
      "Iter: 1/28, Loss:0.8868220448493958\n",
      "Iter: 2/28, Loss:0.9125126600265503\n",
      "Iter: 3/28, Loss:0.9038937091827393\n",
      "Iter: 4/28, Loss:0.9193910360336304\n",
      "Iter: 5/28, Loss:0.8201777935028076\n",
      "Iter: 6/28, Loss:0.8561146855354309\n",
      "Iter: 7/28, Loss:0.7501534819602966\n",
      "Iter: 8/28, Loss:0.8452298045158386\n",
      "Iter: 9/28, Loss:0.9042837023735046\n",
      "Iter: 10/28, Loss:0.8131214380264282\n",
      "Iter: 11/28, Loss:0.8995645642280579\n",
      "Iter: 12/28, Loss:0.8267897367477417\n",
      "Iter: 13/28, Loss:0.8945332169532776\n",
      "Iter: 14/28, Loss:1.0156906843185425\n",
      "Iter: 15/28, Loss:0.900373101234436\n",
      "Iter: 16/28, Loss:0.8345300555229187\n",
      "Iter: 17/28, Loss:0.7885239720344543\n",
      "Iter: 18/28, Loss:0.8268835544586182\n",
      "Iter: 19/28, Loss:0.8804543018341064\n",
      "Iter: 20/28, Loss:0.8018006682395935\n",
      "Iter: 21/28, Loss:0.8784844279289246\n",
      "Iter: 22/28, Loss:0.9127588272094727\n",
      "Iter: 23/28, Loss:0.8303076028823853\n",
      "Iter: 24/28, Loss:0.9176705479621887\n",
      "Iter: 25/28, Loss:0.943373441696167\n",
      "Iter: 26/28, Loss:0.9259992837905884\n",
      "Iter: 27/28, Loss:0.8463788032531738\n",
      "Iter: 28/28, Loss:0.9159541726112366\n",
      "Epoch 14/100: Train loss = 0.873277485370636, Val loss = 1.0144267082214355, Train acc = 0.7171080887616321, Val acc = 0.665140240412135\n",
      "Better params found in epoch = 14, saved params\n",
      "Epoch nro 15/100\n",
      "Iter: 1/28, Loss:0.8010166883468628\n",
      "Iter: 2/28, Loss:0.772621214389801\n",
      "Iter: 3/28, Loss:0.848646879196167\n",
      "Iter: 4/28, Loss:0.958132803440094\n",
      "Iter: 5/28, Loss:0.8430254459381104\n",
      "Iter: 6/28, Loss:0.7961603403091431\n",
      "Iter: 7/28, Loss:0.8545694351196289\n",
      "Iter: 8/28, Loss:0.9190581440925598\n",
      "Iter: 9/28, Loss:0.8516829013824463\n",
      "Iter: 10/28, Loss:0.8211935758590698\n",
      "Iter: 11/28, Loss:0.8318723440170288\n",
      "Iter: 12/28, Loss:0.8645210266113281\n",
      "Iter: 13/28, Loss:0.8433962464332581\n",
      "Iter: 14/28, Loss:0.8352541923522949\n",
      "Iter: 15/28, Loss:0.8928897976875305\n",
      "Iter: 16/28, Loss:0.7834154367446899\n",
      "Iter: 17/28, Loss:0.7988006472587585\n",
      "Iter: 18/28, Loss:0.8965007662773132\n",
      "Iter: 19/28, Loss:0.7724916338920593\n",
      "Iter: 20/28, Loss:0.8379740118980408\n",
      "Iter: 21/28, Loss:0.7787995934486389\n",
      "Iter: 22/28, Loss:0.8074329495429993\n",
      "Iter: 23/28, Loss:0.833487331867218\n",
      "Iter: 24/28, Loss:0.8005982041358948\n",
      "Iter: 25/28, Loss:0.8770788908004761\n",
      "Iter: 26/28, Loss:0.9480881690979004\n",
      "Iter: 27/28, Loss:0.8898982405662537\n",
      "Iter: 28/28, Loss:0.7107703685760498\n",
      "Epoch 15/100: Train loss = 0.8381919264793396, Val loss = 0.976750910282135, Train acc = 0.7229778095919828, Val acc = 0.6697195191757298\n",
      "Better params found in epoch = 15, saved params\n",
      "Epoch nro 16/100\n",
      "Iter: 1/28, Loss:0.8157659769058228\n",
      "Iter: 2/28, Loss:0.8016790151596069\n",
      "Iter: 3/28, Loss:0.800903856754303\n",
      "Iter: 4/28, Loss:0.8846084475517273\n",
      "Iter: 5/28, Loss:0.8813571333885193\n",
      "Iter: 6/28, Loss:0.7917969822883606\n",
      "Iter: 7/28, Loss:0.7998103499412537\n",
      "Iter: 8/28, Loss:0.814002275466919\n",
      "Iter: 9/28, Loss:0.8056893944740295\n",
      "Iter: 10/28, Loss:0.8467404246330261\n",
      "Iter: 11/28, Loss:0.7592965364456177\n",
      "Iter: 12/28, Loss:0.7798613905906677\n",
      "Iter: 13/28, Loss:0.7329831123352051\n",
      "Iter: 14/28, Loss:0.9006361365318298\n",
      "Iter: 15/28, Loss:0.7737910747528076\n",
      "Iter: 16/28, Loss:0.7989019751548767\n",
      "Iter: 17/28, Loss:0.7612054944038391\n",
      "Iter: 18/28, Loss:0.8218377828598022\n",
      "Iter: 19/28, Loss:0.8796261548995972\n",
      "Iter: 20/28, Loss:0.8158050179481506\n",
      "Iter: 21/28, Loss:0.7955036163330078\n",
      "Iter: 22/28, Loss:0.8901061415672302\n",
      "Iter: 23/28, Loss:0.7820548415184021\n",
      "Iter: 24/28, Loss:0.8335282206535339\n",
      "Iter: 25/28, Loss:0.8401726484298706\n",
      "Iter: 26/28, Loss:0.7127848267555237\n",
      "Iter: 27/28, Loss:0.8205918073654175\n",
      "Iter: 28/28, Loss:0.8848016262054443\n",
      "Epoch 16/100: Train loss = 0.8152086138725281, Val loss = 0.930169939994812, Train acc = 0.7345740873299929, Val acc = 0.6926159129937035\n",
      "Better params found in epoch = 16, saved params\n",
      "Epoch nro 17/100\n",
      "Iter: 1/28, Loss:0.8132176995277405\n",
      "Iter: 2/28, Loss:0.8616867661476135\n",
      "Iter: 3/28, Loss:0.8077864050865173\n",
      "Iter: 4/28, Loss:0.790064811706543\n",
      "Iter: 5/28, Loss:0.7773529291152954\n",
      "Iter: 6/28, Loss:0.8315736651420593\n",
      "Iter: 7/28, Loss:0.8436090350151062\n",
      "Iter: 8/28, Loss:0.7210500240325928\n",
      "Iter: 9/28, Loss:0.7734386324882507\n",
      "Iter: 10/28, Loss:0.6718623638153076\n",
      "Iter: 11/28, Loss:0.7546884417533875\n",
      "Iter: 12/28, Loss:0.7554140686988831\n",
      "Iter: 13/28, Loss:0.7889130711555481\n",
      "Iter: 14/28, Loss:0.7527225613594055\n",
      "Iter: 15/28, Loss:0.8063408732414246\n",
      "Iter: 16/28, Loss:0.8564829230308533\n",
      "Iter: 17/28, Loss:0.825645923614502\n",
      "Iter: 18/28, Loss:0.8053799271583557\n",
      "Iter: 19/28, Loss:0.7387872934341431\n",
      "Iter: 20/28, Loss:0.7060147523880005\n",
      "Iter: 21/28, Loss:0.723802387714386\n",
      "Iter: 22/28, Loss:0.6899433732032776\n",
      "Iter: 23/28, Loss:0.784320592880249\n",
      "Iter: 24/28, Loss:0.8821482062339783\n",
      "Iter: 25/28, Loss:0.807965099811554\n",
      "Iter: 26/28, Loss:0.7558985948562622\n",
      "Iter: 27/28, Loss:0.7492091655731201\n",
      "Iter: 28/28, Loss:0.7748256921768188\n",
      "Epoch 17/100: Train loss = 0.7803623080253601, Val loss = 1.0069317817687988, Train acc = 0.7487473156764496, Val acc = 0.6737263880938752\n",
      "Epoch nro 18/100\n",
      "Iter: 1/28, Loss:0.7236464619636536\n",
      "Iter: 2/28, Loss:0.7554787397384644\n",
      "Iter: 3/28, Loss:0.7829492688179016\n",
      "Iter: 4/28, Loss:0.6510974168777466\n",
      "Iter: 5/28, Loss:0.7940316796302795\n",
      "Iter: 6/28, Loss:0.8585491180419922\n",
      "Iter: 7/28, Loss:0.7017181515693665\n",
      "Iter: 8/28, Loss:0.8552621006965637\n",
      "Iter: 9/28, Loss:0.7401872873306274\n",
      "Iter: 10/28, Loss:0.6877853870391846\n",
      "Iter: 11/28, Loss:0.7740187644958496\n",
      "Iter: 12/28, Loss:0.748308002948761\n",
      "Iter: 13/28, Loss:0.8070213198661804\n",
      "Iter: 14/28, Loss:0.7804948091506958\n",
      "Iter: 15/28, Loss:0.7470638751983643\n",
      "Iter: 16/28, Loss:0.661952793598175\n",
      "Iter: 17/28, Loss:0.6865501999855042\n",
      "Iter: 18/28, Loss:0.7605853080749512\n",
      "Iter: 19/28, Loss:0.796667754650116\n",
      "Iter: 20/28, Loss:0.811071515083313\n",
      "Iter: 21/28, Loss:0.6867080330848694\n",
      "Iter: 22/28, Loss:0.7165142297744751\n",
      "Iter: 23/28, Loss:0.7155185341835022\n",
      "Iter: 24/28, Loss:0.7780147790908813\n",
      "Iter: 25/28, Loss:0.7339592576026917\n",
      "Iter: 26/28, Loss:0.6631203889846802\n",
      "Iter: 27/28, Loss:0.7097945213317871\n",
      "Iter: 28/28, Loss:0.8545441031455994\n",
      "Epoch 18/100: Train loss = 0.7493790984153748, Val loss = 0.8937419652938843, Train acc = 0.7614889047959914, Val acc = 0.7012020606754437\n",
      "Better params found in epoch = 18, saved params\n",
      "Epoch nro 19/100\n",
      "Iter: 1/28, Loss:0.7305806279182434\n",
      "Iter: 2/28, Loss:0.6991560459136963\n",
      "Iter: 3/28, Loss:0.7691744565963745\n",
      "Iter: 4/28, Loss:0.6713038682937622\n",
      "Iter: 5/28, Loss:0.6590186953544617\n",
      "Iter: 6/28, Loss:0.6422392725944519\n",
      "Iter: 7/28, Loss:0.7096111178398132\n",
      "Iter: 8/28, Loss:0.7257074117660522\n",
      "Iter: 9/28, Loss:0.7213613986968994\n",
      "Iter: 10/28, Loss:0.791033923625946\n",
      "Iter: 11/28, Loss:0.8444275259971619\n",
      "Iter: 12/28, Loss:0.8260892629623413\n",
      "Iter: 13/28, Loss:0.6838154792785645\n",
      "Iter: 14/28, Loss:0.6784784197807312\n",
      "Iter: 15/28, Loss:0.8120296597480774\n",
      "Iter: 16/28, Loss:0.7510075569152832\n",
      "Iter: 17/28, Loss:0.7499966025352478\n",
      "Iter: 18/28, Loss:0.8411394953727722\n",
      "Iter: 19/28, Loss:0.6651008725166321\n",
      "Iter: 20/28, Loss:0.6689653396606445\n",
      "Iter: 21/28, Loss:0.7190181016921997\n",
      "Iter: 22/28, Loss:0.7333523035049438\n",
      "Iter: 23/28, Loss:0.7296459078788757\n",
      "Iter: 24/28, Loss:0.6462136507034302\n",
      "Iter: 25/28, Loss:0.7012968063354492\n",
      "Iter: 26/28, Loss:0.8346540927886963\n",
      "Iter: 27/28, Loss:0.7250412702560425\n",
      "Iter: 28/28, Loss:0.7475895881652832\n",
      "Epoch 19/100: Train loss = 0.7313231825828552, Val loss = 0.8611840009689331, Train acc = 0.7629205440229062, Val acc = 0.7132226674298798\n",
      "Better params found in epoch = 19, saved params\n",
      "Epoch nro 20/100\n",
      "Iter: 1/28, Loss:0.6421651840209961\n",
      "Iter: 2/28, Loss:0.6761648058891296\n",
      "Iter: 3/28, Loss:0.7643750905990601\n",
      "Iter: 4/28, Loss:0.791653573513031\n",
      "Iter: 5/28, Loss:0.7196590900421143\n",
      "Iter: 6/28, Loss:0.6865518093109131\n",
      "Iter: 7/28, Loss:0.7163852453231812\n",
      "Iter: 8/28, Loss:0.7457899451255798\n",
      "Iter: 9/28, Loss:0.6661787629127502\n",
      "Iter: 10/28, Loss:0.7019644379615784\n",
      "Iter: 11/28, Loss:0.7626910209655762\n",
      "Iter: 12/28, Loss:0.7157034873962402\n",
      "Iter: 13/28, Loss:0.6683800220489502\n",
      "Iter: 14/28, Loss:0.5938055515289307\n",
      "Iter: 15/28, Loss:0.6893789768218994\n",
      "Iter: 16/28, Loss:0.6683412194252014\n",
      "Iter: 17/28, Loss:0.7660321593284607\n",
      "Iter: 18/28, Loss:0.7181136608123779\n",
      "Iter: 19/28, Loss:0.5926848649978638\n",
      "Iter: 20/28, Loss:0.7207374572753906\n",
      "Iter: 21/28, Loss:0.6621097922325134\n",
      "Iter: 22/28, Loss:0.7270035743713379\n",
      "Iter: 23/28, Loss:0.7491276264190674\n",
      "Iter: 24/28, Loss:0.6735727787017822\n",
      "Iter: 25/28, Loss:0.618996262550354\n",
      "Iter: 26/28, Loss:0.6811659336090088\n",
      "Iter: 27/28, Loss:0.6265238523483276\n",
      "Iter: 28/28, Loss:0.6766042113304138\n",
      "Epoch 20/100: Train loss = 0.6936379075050354, Val loss = 0.9083946943283081, Train acc = 0.7805297065139585, Val acc = 0.7029192902117917\n",
      "Epoch nro 21/100\n",
      "Iter: 1/28, Loss:0.6527287364006042\n",
      "Iter: 2/28, Loss:0.6228753328323364\n",
      "Iter: 3/28, Loss:0.6383910775184631\n",
      "Iter: 4/28, Loss:0.6519467830657959\n",
      "Iter: 5/28, Loss:0.7149052619934082\n",
      "Iter: 6/28, Loss:0.7115181088447571\n",
      "Iter: 7/28, Loss:0.6096087694168091\n",
      "Iter: 8/28, Loss:0.7866409420967102\n",
      "Iter: 9/28, Loss:0.6100174784660339\n",
      "Iter: 10/28, Loss:0.710491955280304\n",
      "Iter: 11/28, Loss:0.5687330365180969\n",
      "Iter: 12/28, Loss:0.6497859358787537\n",
      "Iter: 13/28, Loss:0.7305940389633179\n",
      "Iter: 14/28, Loss:0.6575201749801636\n",
      "Iter: 15/28, Loss:0.6545158624649048\n",
      "Iter: 16/28, Loss:0.6118982434272766\n",
      "Iter: 17/28, Loss:0.6669960618019104\n",
      "Iter: 18/28, Loss:0.602568507194519\n",
      "Iter: 19/28, Loss:0.5955958366394043\n",
      "Iter: 20/28, Loss:0.7066448926925659\n",
      "Iter: 21/28, Loss:0.6317014694213867\n",
      "Iter: 22/28, Loss:0.6295610666275024\n",
      "Iter: 23/28, Loss:0.7333952188491821\n",
      "Iter: 24/28, Loss:0.594815731048584\n",
      "Iter: 25/28, Loss:0.6589475274085999\n",
      "Iter: 26/28, Loss:0.6987228393554688\n",
      "Iter: 27/28, Loss:0.6959060430526733\n",
      "Iter: 28/28, Loss:0.7050594091415405\n",
      "Epoch 21/100: Train loss = 0.6607888340950012, Val loss = 0.8160977959632874, Train acc = 0.7896921975662133, Val acc = 0.7378362907842015\n",
      "Better params found in epoch = 21, saved params\n",
      "Epoch nro 22/100\n",
      "Iter: 1/28, Loss:0.6396111249923706\n",
      "Iter: 2/28, Loss:0.6297310590744019\n",
      "Iter: 3/28, Loss:0.6469990611076355\n",
      "Iter: 4/28, Loss:0.6669877171516418\n",
      "Iter: 5/28, Loss:0.6487482190132141\n",
      "Iter: 6/28, Loss:0.7108088731765747\n",
      "Iter: 7/28, Loss:0.6471646428108215\n",
      "Iter: 8/28, Loss:0.7283938527107239\n",
      "Iter: 9/28, Loss:0.6572957634925842\n",
      "Iter: 10/28, Loss:0.6204792857170105\n",
      "Iter: 11/28, Loss:0.628781795501709\n",
      "Iter: 12/28, Loss:0.5703127980232239\n",
      "Iter: 13/28, Loss:0.6094787120819092\n",
      "Iter: 14/28, Loss:0.6720125079154968\n",
      "Iter: 15/28, Loss:0.6515852808952332\n",
      "Iter: 16/28, Loss:0.6723304986953735\n",
      "Iter: 17/28, Loss:0.7139067053794861\n",
      "Iter: 18/28, Loss:0.6683369278907776\n",
      "Iter: 19/28, Loss:0.6430803537368774\n",
      "Iter: 20/28, Loss:0.6766313314437866\n",
      "Iter: 21/28, Loss:0.5613303780555725\n",
      "Iter: 22/28, Loss:0.6275709271430969\n",
      "Iter: 23/28, Loss:0.7008528709411621\n",
      "Iter: 24/28, Loss:0.5721068382263184\n",
      "Iter: 25/28, Loss:0.6806784868240356\n",
      "Iter: 26/28, Loss:0.6480802297592163\n",
      "Iter: 27/28, Loss:0.6610020995140076\n",
      "Iter: 28/28, Loss:0.703750729560852\n",
      "Epoch 22/100: Train loss = 0.6520732641220093, Val loss = 0.8253948092460632, Train acc = 0.7978525411596278, Val acc = 0.725243274184316\n",
      "Epoch nro 23/100\n",
      "Iter: 1/28, Loss:0.5857102274894714\n",
      "Iter: 2/28, Loss:0.7124698758125305\n",
      "Iter: 3/28, Loss:0.6427899599075317\n",
      "Iter: 4/28, Loss:0.5606600642204285\n",
      "Iter: 5/28, Loss:0.6089516878128052\n",
      "Iter: 6/28, Loss:0.6276816129684448\n",
      "Iter: 7/28, Loss:0.6551679968833923\n",
      "Iter: 8/28, Loss:0.7579811215400696\n",
      "Iter: 9/28, Loss:0.6886253952980042\n",
      "Iter: 10/28, Loss:0.6283374428749084\n",
      "Iter: 11/28, Loss:0.5113255977630615\n",
      "Iter: 12/28, Loss:0.6950967311859131\n",
      "Iter: 13/28, Loss:0.6452745199203491\n",
      "Iter: 14/28, Loss:0.5964852571487427\n",
      "Iter: 15/28, Loss:0.5919139981269836\n",
      "Iter: 16/28, Loss:0.6269993185997009\n",
      "Iter: 17/28, Loss:0.578822135925293\n",
      "Iter: 18/28, Loss:0.6857669949531555\n",
      "Iter: 19/28, Loss:0.6541986465454102\n",
      "Iter: 20/28, Loss:0.5849310755729675\n",
      "Iter: 21/28, Loss:0.5697644948959351\n",
      "Iter: 22/28, Loss:0.6791278123855591\n",
      "Iter: 23/28, Loss:0.6113312244415283\n",
      "Iter: 24/28, Loss:0.6466178297996521\n",
      "Iter: 25/28, Loss:0.6722897291183472\n",
      "Iter: 26/28, Loss:0.5582457780838013\n",
      "Iter: 27/28, Loss:0.5638049840927124\n",
      "Iter: 28/28, Loss:0.6351370215415955\n",
      "Epoch 23/100: Train loss = 0.6276967525482178, Val loss = 0.8116580247879028, Train acc = 0.8045812455261274, Val acc = 0.7349742415569548\n",
      "Better params found in epoch = 23, saved params\n",
      "Epoch nro 24/100\n",
      "Iter: 1/28, Loss:0.6247434616088867\n",
      "Iter: 2/28, Loss:0.6796668767929077\n",
      "Iter: 3/28, Loss:0.6534422636032104\n",
      "Iter: 4/28, Loss:0.6826217770576477\n",
      "Iter: 5/28, Loss:0.5901557207107544\n",
      "Iter: 6/28, Loss:0.6114263534545898\n",
      "Iter: 7/28, Loss:0.5550550222396851\n",
      "Iter: 8/28, Loss:0.5551044344902039\n",
      "Iter: 9/28, Loss:0.5799058079719543\n",
      "Iter: 10/28, Loss:0.6005519032478333\n",
      "Iter: 11/28, Loss:0.5776689648628235\n",
      "Iter: 12/28, Loss:0.5493963956832886\n",
      "Iter: 13/28, Loss:0.6403647661209106\n",
      "Iter: 14/28, Loss:0.6881914138793945\n",
      "Iter: 15/28, Loss:0.49855050444602966\n",
      "Iter: 16/28, Loss:0.5584444403648376\n",
      "Iter: 17/28, Loss:0.6818128824234009\n",
      "Iter: 18/28, Loss:0.5623685717582703\n",
      "Iter: 19/28, Loss:0.6294208765029907\n",
      "Iter: 20/28, Loss:0.5225461721420288\n",
      "Iter: 21/28, Loss:0.5028456449508667\n",
      "Iter: 22/28, Loss:0.5752026438713074\n",
      "Iter: 23/28, Loss:0.6088165640830994\n",
      "Iter: 24/28, Loss:0.6119182705879211\n",
      "Iter: 25/28, Loss:0.642723560333252\n",
      "Iter: 26/28, Loss:0.6534828543663025\n",
      "Iter: 27/28, Loss:0.535664439201355\n",
      "Iter: 28/28, Loss:0.5764168500900269\n",
      "Epoch 24/100: Train loss = 0.598160982131958, Val loss = 0.8504953980445862, Train acc = 0.8114531138153186, Val acc = 0.7132226674298798\n",
      "Epoch nro 25/100\n",
      "Iter: 1/28, Loss:0.6196508407592773\n",
      "Iter: 2/28, Loss:0.6405649781227112\n",
      "Iter: 3/28, Loss:0.5822297930717468\n",
      "Iter: 4/28, Loss:0.5390216708183289\n",
      "Iter: 5/28, Loss:0.5832828879356384\n",
      "Iter: 6/28, Loss:0.5558332800865173\n",
      "Iter: 7/28, Loss:0.534730851650238\n",
      "Iter: 8/28, Loss:0.6039350628852844\n",
      "Iter: 9/28, Loss:0.5729265213012695\n",
      "Iter: 10/28, Loss:0.6062226891517639\n",
      "Iter: 11/28, Loss:0.6848717331886292\n",
      "Iter: 12/28, Loss:0.5602543354034424\n",
      "Iter: 13/28, Loss:0.6167482137680054\n",
      "Iter: 14/28, Loss:0.6372596621513367\n",
      "Iter: 15/28, Loss:0.592322051525116\n",
      "Iter: 16/28, Loss:0.5494062900543213\n",
      "Iter: 17/28, Loss:0.5860455632209778\n",
      "Iter: 18/28, Loss:0.6163709759712219\n",
      "Iter: 19/28, Loss:0.5599766969680786\n",
      "Iter: 20/28, Loss:0.5986344218254089\n",
      "Iter: 21/28, Loss:0.5338611006736755\n",
      "Iter: 22/28, Loss:0.5943618416786194\n",
      "Iter: 23/28, Loss:0.6060242056846619\n",
      "Iter: 24/28, Loss:0.7129683494567871\n",
      "Iter: 25/28, Loss:0.559493362903595\n",
      "Iter: 26/28, Loss:0.6025024056434631\n",
      "Iter: 27/28, Loss:0.5279327630996704\n",
      "Iter: 28/28, Loss:0.5978648662567139\n",
      "Epoch 25/100: Train loss = 0.5919749736785889, Val loss = 0.7908881306648254, Train acc = 0.8214745884037222, Val acc = 0.7218088151116199\n",
      "Better params found in epoch = 25, saved params\n",
      "Epoch nro 26/100\n",
      "Iter: 1/28, Loss:0.5913683176040649\n",
      "Iter: 2/28, Loss:0.6582534313201904\n",
      "Iter: 3/28, Loss:0.5059666037559509\n",
      "Iter: 4/28, Loss:0.4857514500617981\n",
      "Iter: 5/28, Loss:0.5760235786437988\n",
      "Iter: 6/28, Loss:0.6737717390060425\n",
      "Iter: 7/28, Loss:0.6191725134849548\n",
      "Iter: 8/28, Loss:0.5146138072013855\n",
      "Iter: 9/28, Loss:0.6601558923721313\n",
      "Iter: 10/28, Loss:0.6255452036857605\n",
      "Iter: 11/28, Loss:0.545976459980011\n",
      "Iter: 12/28, Loss:0.5429353713989258\n",
      "Iter: 13/28, Loss:0.5646663308143616\n",
      "Iter: 14/28, Loss:0.5833829641342163\n",
      "Iter: 15/28, Loss:0.5226781368255615\n",
      "Iter: 16/28, Loss:0.6247714757919312\n",
      "Iter: 17/28, Loss:0.48355719447135925\n",
      "Iter: 18/28, Loss:0.4654653072357178\n",
      "Iter: 19/28, Loss:0.6039057374000549\n",
      "Iter: 20/28, Loss:0.5604584217071533\n",
      "Iter: 21/28, Loss:0.5467605590820312\n",
      "Iter: 22/28, Loss:0.6479923129081726\n",
      "Iter: 23/28, Loss:0.5470311641693115\n",
      "Iter: 24/28, Loss:0.5656828880310059\n",
      "Iter: 25/28, Loss:0.5641290545463562\n",
      "Iter: 26/28, Loss:0.49813881516456604\n",
      "Iter: 27/28, Loss:0.6389163732528687\n",
      "Iter: 28/28, Loss:0.5686625242233276\n",
      "Epoch 26/100: Train loss = 0.5709189772605896, Val loss = 0.727369487285614, Train acc = 0.8194702934860415, Val acc = 0.7670291929021179\n",
      "Better params found in epoch = 26, saved params\n",
      "Epoch nro 27/100\n",
      "Iter: 1/28, Loss:0.5753259062767029\n",
      "Iter: 2/28, Loss:0.47874486446380615\n",
      "Iter: 3/28, Loss:0.6054009795188904\n",
      "Iter: 4/28, Loss:0.5642969012260437\n",
      "Iter: 5/28, Loss:0.5556442141532898\n",
      "Iter: 6/28, Loss:0.5750654339790344\n",
      "Iter: 7/28, Loss:0.5151423811912537\n",
      "Iter: 8/28, Loss:0.5728349685668945\n",
      "Iter: 9/28, Loss:0.43626633286476135\n",
      "Iter: 10/28, Loss:0.5523186326026917\n",
      "Iter: 11/28, Loss:0.5268034934997559\n",
      "Iter: 12/28, Loss:0.5840523838996887\n",
      "Iter: 13/28, Loss:0.5673991441726685\n",
      "Iter: 14/28, Loss:0.5117989182472229\n",
      "Iter: 15/28, Loss:0.47220396995544434\n",
      "Iter: 16/28, Loss:0.5191221833229065\n",
      "Iter: 17/28, Loss:0.48357295989990234\n",
      "Iter: 18/28, Loss:0.5229756236076355\n",
      "Iter: 19/28, Loss:0.5158489942550659\n",
      "Iter: 20/28, Loss:0.49382856488227844\n",
      "Iter: 21/28, Loss:0.6030239462852478\n",
      "Iter: 22/28, Loss:0.5240408182144165\n",
      "Iter: 23/28, Loss:0.43322721123695374\n",
      "Iter: 24/28, Loss:0.5265767574310303\n",
      "Iter: 25/28, Loss:0.5166211128234863\n",
      "Iter: 26/28, Loss:0.5803526639938354\n",
      "Iter: 27/28, Loss:0.5779270529747009\n",
      "Iter: 28/28, Loss:0.6315258145332336\n",
      "Epoch 27/100: Train loss = 0.5364980101585388, Val loss = 0.7357766628265381, Train acc = 0.8347888332140301, Val acc = 0.7532913566113337\n",
      "Epoch nro 28/100\n",
      "Iter: 1/28, Loss:0.45134878158569336\n",
      "Iter: 2/28, Loss:0.5260809659957886\n",
      "Iter: 3/28, Loss:0.4560054540634155\n",
      "Iter: 4/28, Loss:0.5777920484542847\n",
      "Iter: 5/28, Loss:0.45967763662338257\n",
      "Iter: 6/28, Loss:0.5326258540153503\n",
      "Iter: 7/28, Loss:0.4894275963306427\n",
      "Iter: 8/28, Loss:0.4503113627433777\n",
      "Iter: 9/28, Loss:0.5488408207893372\n",
      "Iter: 10/28, Loss:0.41660770773887634\n",
      "Iter: 11/28, Loss:0.6142315864562988\n",
      "Iter: 12/28, Loss:0.6427307724952698\n",
      "Iter: 13/28, Loss:0.5912327170372009\n",
      "Iter: 14/28, Loss:0.4667724072933197\n",
      "Iter: 15/28, Loss:0.5954753160476685\n",
      "Iter: 16/28, Loss:0.5083155035972595\n",
      "Iter: 17/28, Loss:0.5083431005477905\n",
      "Iter: 18/28, Loss:0.46461495757102966\n",
      "Iter: 19/28, Loss:0.5610693693161011\n",
      "Iter: 20/28, Loss:0.551392674446106\n",
      "Iter: 21/28, Loss:0.5871638655662537\n",
      "Iter: 22/28, Loss:0.5534312129020691\n",
      "Iter: 23/28, Loss:0.5671350359916687\n",
      "Iter: 24/28, Loss:0.6382014751434326\n",
      "Iter: 25/28, Loss:0.5822767615318298\n",
      "Iter: 26/28, Loss:0.5094423890113831\n",
      "Iter: 27/28, Loss:0.5198503136634827\n",
      "Iter: 28/28, Loss:0.548883318901062\n",
      "Epoch 28/100: Train loss = 0.5328314900398254, Val loss = 0.7574762105941772, Train acc = 0.8357909806728704, Val acc = 0.748712077847739\n",
      "Epoch nro 29/100\n",
      "Iter: 1/28, Loss:0.5446426272392273\n",
      "Iter: 2/28, Loss:0.5260441303253174\n",
      "Iter: 3/28, Loss:0.5430739521980286\n",
      "Iter: 4/28, Loss:0.49931463599205017\n",
      "Iter: 5/28, Loss:0.5395093560218811\n",
      "Iter: 6/28, Loss:0.5067967772483826\n",
      "Iter: 7/28, Loss:0.4996228814125061\n",
      "Iter: 8/28, Loss:0.6285073161125183\n",
      "Iter: 9/28, Loss:0.49673575162887573\n",
      "Iter: 10/28, Loss:0.49633151292800903\n",
      "Iter: 11/28, Loss:0.49058857560157776\n",
      "Iter: 12/28, Loss:0.5501089096069336\n",
      "Iter: 13/28, Loss:0.5061218738555908\n",
      "Iter: 14/28, Loss:0.5285614132881165\n",
      "Iter: 15/28, Loss:0.526746928691864\n",
      "Iter: 16/28, Loss:0.46517083048820496\n",
      "Iter: 17/28, Loss:0.5442138910293579\n",
      "Iter: 18/28, Loss:0.49598780274391174\n",
      "Iter: 19/28, Loss:0.45266056060791016\n",
      "Iter: 20/28, Loss:0.529891848564148\n",
      "Iter: 21/28, Loss:0.5492463707923889\n",
      "Iter: 22/28, Loss:0.4945111572742462\n",
      "Iter: 23/28, Loss:0.4228765368461609\n",
      "Iter: 24/28, Loss:0.49209216237068176\n",
      "Iter: 25/28, Loss:0.4609770178794861\n",
      "Iter: 26/28, Loss:0.5238999128341675\n",
      "Iter: 27/28, Loss:0.4741674065589905\n",
      "Iter: 28/28, Loss:0.4884677231311798\n",
      "Epoch 29/100: Train loss = 0.5098882913589478, Val loss = 0.6996689438819885, Train acc = 0.8476735862562634, Val acc = 0.7710360618202633\n",
      "Better params found in epoch = 29, saved params\n",
      "Epoch nro 30/100\n",
      "Iter: 1/28, Loss:0.43148207664489746\n",
      "Iter: 2/28, Loss:0.45444443821907043\n",
      "Iter: 3/28, Loss:0.4527234137058258\n",
      "Iter: 4/28, Loss:0.5114749073982239\n",
      "Iter: 5/28, Loss:0.520818829536438\n",
      "Iter: 6/28, Loss:0.5386183261871338\n",
      "Iter: 7/28, Loss:0.4656149744987488\n",
      "Iter: 8/28, Loss:0.4490484297275543\n",
      "Iter: 9/28, Loss:0.5233086943626404\n",
      "Iter: 10/28, Loss:0.402969628572464\n",
      "Iter: 11/28, Loss:0.5595797300338745\n",
      "Iter: 12/28, Loss:0.4233223497867584\n",
      "Iter: 13/28, Loss:0.4631640911102295\n",
      "Iter: 14/28, Loss:0.48484790325164795\n",
      "Iter: 15/28, Loss:0.45628872513771057\n",
      "Iter: 16/28, Loss:0.49945539236068726\n",
      "Iter: 17/28, Loss:0.5214278101921082\n",
      "Iter: 18/28, Loss:0.504033625125885\n",
      "Iter: 19/28, Loss:0.428769052028656\n",
      "Iter: 20/28, Loss:0.5370217561721802\n",
      "Iter: 21/28, Loss:0.45082247257232666\n",
      "Iter: 22/28, Loss:0.48472872376441956\n",
      "Iter: 23/28, Loss:0.5059975981712341\n",
      "Iter: 24/28, Loss:0.458418607711792\n",
      "Iter: 25/28, Loss:0.49726030230522156\n",
      "Iter: 26/28, Loss:0.5741486549377441\n",
      "Iter: 27/28, Loss:0.5327193737030029\n",
      "Iter: 28/28, Loss:0.5386336445808411\n",
      "Epoch 30/100: Train loss = 0.48825520277023315, Val loss = 0.6704846024513245, Train acc = 0.8471009305654975, Val acc = 0.7733257012020607\n",
      "Better params found in epoch = 30, saved params\n",
      "Epoch nro 31/100\n",
      "Iter: 1/28, Loss:0.42111706733703613\n",
      "Iter: 2/28, Loss:0.4399788975715637\n",
      "Iter: 3/28, Loss:0.47056201100349426\n",
      "Iter: 4/28, Loss:0.4761945903301239\n",
      "Iter: 5/28, Loss:0.43988609313964844\n",
      "Iter: 6/28, Loss:0.44910162687301636\n",
      "Iter: 7/28, Loss:0.4533405303955078\n",
      "Iter: 8/28, Loss:0.4573242962360382\n",
      "Iter: 9/28, Loss:0.4941575825214386\n",
      "Iter: 10/28, Loss:0.4983406066894531\n",
      "Iter: 11/28, Loss:0.5122867822647095\n",
      "Iter: 12/28, Loss:0.4208621084690094\n",
      "Iter: 13/28, Loss:0.5194908976554871\n",
      "Iter: 14/28, Loss:0.44112110137939453\n",
      "Iter: 15/28, Loss:0.5564891695976257\n",
      "Iter: 16/28, Loss:0.5101358890533447\n",
      "Iter: 17/28, Loss:0.4723134934902191\n",
      "Iter: 18/28, Loss:0.46585115790367126\n",
      "Iter: 19/28, Loss:0.47216400504112244\n",
      "Iter: 20/28, Loss:0.4490901827812195\n",
      "Iter: 21/28, Loss:0.5483700037002563\n",
      "Iter: 22/28, Loss:0.45616427063941956\n",
      "Iter: 23/28, Loss:0.5088832378387451\n",
      "Iter: 24/28, Loss:0.4458080530166626\n",
      "Iter: 25/28, Loss:0.4963638186454773\n",
      "Iter: 26/28, Loss:0.4890241324901581\n",
      "Iter: 27/28, Loss:0.46793073415756226\n",
      "Iter: 28/28, Loss:0.4727821350097656\n",
      "Epoch 31/100: Train loss = 0.4751834273338318, Val loss = 0.7212651371955872, Train acc = 0.8538296349319972, Val acc = 0.7624499141385231\n",
      "Epoch nro 32/100\n",
      "Iter: 1/28, Loss:0.5076002478599548\n",
      "Iter: 2/28, Loss:0.43081581592559814\n",
      "Iter: 3/28, Loss:0.5195789933204651\n",
      "Iter: 4/28, Loss:0.4735228419303894\n",
      "Iter: 5/28, Loss:0.4455963671207428\n",
      "Iter: 6/28, Loss:0.47525590658187866\n",
      "Iter: 7/28, Loss:0.3799322545528412\n",
      "Iter: 8/28, Loss:0.4694654643535614\n",
      "Iter: 9/28, Loss:0.40799522399902344\n",
      "Iter: 10/28, Loss:0.5092666149139404\n",
      "Iter: 11/28, Loss:0.47328633069992065\n",
      "Iter: 12/28, Loss:0.4678630232810974\n",
      "Iter: 13/28, Loss:0.590222179889679\n",
      "Iter: 14/28, Loss:0.4745885133743286\n",
      "Iter: 15/28, Loss:0.48459377884864807\n",
      "Iter: 16/28, Loss:0.4257681965827942\n",
      "Iter: 17/28, Loss:0.49414122104644775\n",
      "Iter: 18/28, Loss:0.4908719062805176\n",
      "Iter: 19/28, Loss:0.5133703351020813\n",
      "Iter: 20/28, Loss:0.47362759709358215\n",
      "Iter: 21/28, Loss:0.4670797884464264\n",
      "Iter: 22/28, Loss:0.5060988068580627\n",
      "Iter: 23/28, Loss:0.411241352558136\n",
      "Iter: 24/28, Loss:0.5031473636627197\n",
      "Iter: 25/28, Loss:0.5106229186058044\n",
      "Iter: 26/28, Loss:0.4681243598461151\n",
      "Iter: 27/28, Loss:0.42166668176651\n",
      "Iter: 28/28, Loss:0.48157888650894165\n",
      "Epoch 32/100: Train loss = 0.4741758704185486, Val loss = 0.6747423410415649, Train acc = 0.8535433070866142, Val acc = 0.7801946193474528\n",
      "Epoch nro 33/100\n",
      "Iter: 1/28, Loss:0.46389222145080566\n",
      "Iter: 2/28, Loss:0.3961804509162903\n",
      "Iter: 3/28, Loss:0.495402991771698\n",
      "Iter: 4/28, Loss:0.3751201927661896\n",
      "Iter: 5/28, Loss:0.4609391689300537\n",
      "Iter: 6/28, Loss:0.5005298852920532\n",
      "Iter: 7/28, Loss:0.4828878343105316\n",
      "Iter: 8/28, Loss:0.44205421209335327\n",
      "Iter: 9/28, Loss:0.417473167181015\n",
      "Iter: 10/28, Loss:0.5330644249916077\n",
      "Iter: 11/28, Loss:0.4146559536457062\n",
      "Iter: 12/28, Loss:0.5386394262313843\n",
      "Iter: 13/28, Loss:0.46828705072402954\n",
      "Iter: 14/28, Loss:0.551190197467804\n",
      "Iter: 15/28, Loss:0.49453994631767273\n",
      "Iter: 16/28, Loss:0.3919582664966583\n",
      "Iter: 17/28, Loss:0.4792083501815796\n",
      "Iter: 18/28, Loss:0.45760437846183777\n",
      "Iter: 19/28, Loss:0.4529944062232971\n",
      "Iter: 20/28, Loss:0.37984564900398254\n",
      "Iter: 21/28, Loss:0.4357971251010895\n",
      "Iter: 22/28, Loss:0.4372531771659851\n",
      "Iter: 23/28, Loss:0.4191342890262604\n",
      "Iter: 24/28, Loss:0.4467735290527344\n",
      "Iter: 25/28, Loss:0.5220001935958862\n",
      "Iter: 26/28, Loss:0.5335172414779663\n",
      "Iter: 27/28, Loss:0.4554319977760315\n",
      "Iter: 28/28, Loss:0.4395641088485718\n",
      "Epoch 33/100: Train loss = 0.4602121114730835, Val loss = 0.6712265610694885, Train acc = 0.8585540443808161, Val acc = 0.7801946193474528\n",
      "Epoch nro 34/100\n",
      "Iter: 1/28, Loss:0.4755760133266449\n",
      "Iter: 2/28, Loss:0.4374675154685974\n",
      "Iter: 3/28, Loss:0.41948965191841125\n",
      "Iter: 4/28, Loss:0.39459818601608276\n",
      "Iter: 5/28, Loss:0.3799213469028473\n",
      "Iter: 6/28, Loss:0.4070465862751007\n",
      "Iter: 7/28, Loss:0.4513055980205536\n",
      "Iter: 8/28, Loss:0.3877726197242737\n",
      "Iter: 9/28, Loss:0.42574283480644226\n",
      "Iter: 10/28, Loss:0.4051688015460968\n",
      "Iter: 11/28, Loss:0.36873432993888855\n",
      "Iter: 12/28, Loss:0.4203350841999054\n",
      "Iter: 13/28, Loss:0.4176357686519623\n",
      "Iter: 14/28, Loss:0.5095775723457336\n",
      "Iter: 15/28, Loss:0.554588258266449\n",
      "Iter: 16/28, Loss:0.47565871477127075\n",
      "Iter: 17/28, Loss:0.4554330110549927\n",
      "Iter: 18/28, Loss:0.49113619327545166\n",
      "Iter: 19/28, Loss:0.494773805141449\n",
      "Iter: 20/28, Loss:0.39050722122192383\n",
      "Iter: 21/28, Loss:0.4419136345386505\n",
      "Iter: 22/28, Loss:0.4638063609600067\n",
      "Iter: 23/28, Loss:0.5349282026290894\n",
      "Iter: 24/28, Loss:0.5207329392433167\n",
      "Iter: 25/28, Loss:0.3783233165740967\n",
      "Iter: 26/28, Loss:0.47238752245903015\n",
      "Iter: 27/28, Loss:0.3832886219024658\n",
      "Iter: 28/28, Loss:0.34550386667251587\n",
      "Epoch 34/100: Train loss = 0.43940553069114685, Val loss = 0.6208556294441223, Train acc = 0.8671438797423049, Val acc = 0.8065254722381225\n",
      "Better params found in epoch = 34, saved params\n",
      "Epoch nro 35/100\n",
      "Iter: 1/28, Loss:0.4056236743927002\n",
      "Iter: 2/28, Loss:0.44195932149887085\n",
      "Iter: 3/28, Loss:0.4485858976840973\n",
      "Iter: 4/28, Loss:0.38122105598449707\n",
      "Iter: 5/28, Loss:0.4302251935005188\n",
      "Iter: 6/28, Loss:0.40011927485466003\n",
      "Iter: 7/28, Loss:0.38910549879074097\n",
      "Iter: 8/28, Loss:0.48637086153030396\n",
      "Iter: 9/28, Loss:0.3996651768684387\n",
      "Iter: 10/28, Loss:0.4284249544143677\n",
      "Iter: 11/28, Loss:0.4102965295314789\n",
      "Iter: 12/28, Loss:0.45276445150375366\n",
      "Iter: 13/28, Loss:0.4288211464881897\n",
      "Iter: 14/28, Loss:0.39551329612731934\n",
      "Iter: 15/28, Loss:0.3987877368927002\n",
      "Iter: 16/28, Loss:0.48344892263412476\n",
      "Iter: 17/28, Loss:0.5206893086433411\n",
      "Iter: 18/28, Loss:0.4024079442024231\n",
      "Iter: 19/28, Loss:0.48277536034584045\n",
      "Iter: 20/28, Loss:0.45221054553985596\n",
      "Iter: 21/28, Loss:0.42435139417648315\n",
      "Iter: 22/28, Loss:0.5329126119613647\n",
      "Iter: 23/28, Loss:0.4932217597961426\n",
      "Iter: 24/28, Loss:0.4490375518798828\n",
      "Iter: 25/28, Loss:0.4657955467700958\n",
      "Iter: 26/28, Loss:0.482684850692749\n",
      "Iter: 27/28, Loss:0.409796804189682\n",
      "Iter: 28/28, Loss:0.431954562664032\n",
      "Epoch 35/100: Train loss = 0.44031327962875366, Val loss = 0.6264309287071228, Train acc = 0.8648532569792412, Val acc = 0.7893531768746422\n",
      "Epoch nro 36/100\n",
      "Iter: 1/28, Loss:0.4308541417121887\n",
      "Iter: 2/28, Loss:0.4430103600025177\n",
      "Iter: 3/28, Loss:0.4994524121284485\n",
      "Iter: 4/28, Loss:0.44939735531806946\n",
      "Iter: 5/28, Loss:0.41427522897720337\n",
      "Iter: 6/28, Loss:0.5137308835983276\n",
      "Iter: 7/28, Loss:0.43471845984458923\n",
      "Iter: 8/28, Loss:0.5291364789009094\n",
      "Iter: 9/28, Loss:0.4452521800994873\n",
      "Iter: 10/28, Loss:0.3790314793586731\n",
      "Iter: 11/28, Loss:0.46578946709632874\n",
      "Iter: 12/28, Loss:0.4413968026638031\n",
      "Iter: 13/28, Loss:0.48218104243278503\n",
      "Iter: 14/28, Loss:0.39645034074783325\n",
      "Iter: 15/28, Loss:0.4008236825466156\n",
      "Iter: 16/28, Loss:0.3806792199611664\n",
      "Iter: 17/28, Loss:0.41514429450035095\n",
      "Iter: 18/28, Loss:0.456048846244812\n",
      "Iter: 19/28, Loss:0.4412773549556732\n",
      "Iter: 20/28, Loss:0.4667096734046936\n",
      "Iter: 21/28, Loss:0.4832766354084015\n",
      "Iter: 22/28, Loss:0.40161335468292236\n",
      "Iter: 23/28, Loss:0.4552496075630188\n",
      "Iter: 24/28, Loss:0.44891080260276794\n",
      "Iter: 25/28, Loss:0.4436696469783783\n",
      "Iter: 26/28, Loss:0.44061288237571716\n",
      "Iter: 27/28, Loss:0.3725636899471283\n",
      "Iter: 28/28, Loss:0.4220160245895386\n",
      "Epoch 36/100: Train loss = 0.4411882758140564, Val loss = 0.6631972193717957, Train acc = 0.8651395848246242, Val acc = 0.7876359473382942\n",
      "Epoch nro 37/100\n",
      "Iter: 1/28, Loss:0.3879614472389221\n",
      "Iter: 2/28, Loss:0.41802018880844116\n",
      "Iter: 3/28, Loss:0.4966619610786438\n",
      "Iter: 4/28, Loss:0.4639919102191925\n",
      "Iter: 5/28, Loss:0.3883245885372162\n",
      "Iter: 6/28, Loss:0.3824335038661957\n",
      "Iter: 7/28, Loss:0.4173749089241028\n",
      "Iter: 8/28, Loss:0.3542279601097107\n",
      "Iter: 9/28, Loss:0.3978584408760071\n",
      "Iter: 10/28, Loss:0.420379102230072\n",
      "Iter: 11/28, Loss:0.45689767599105835\n",
      "Iter: 12/28, Loss:0.5445471405982971\n",
      "Iter: 13/28, Loss:0.4442380666732788\n",
      "Iter: 14/28, Loss:0.37909844517707825\n",
      "Iter: 15/28, Loss:0.4900828003883362\n",
      "Iter: 16/28, Loss:0.3664310872554779\n",
      "Iter: 17/28, Loss:0.4036504626274109\n",
      "Iter: 18/28, Loss:0.49399611353874207\n",
      "Iter: 19/28, Loss:0.3579549789428711\n",
      "Iter: 20/28, Loss:0.3720055818557739\n",
      "Iter: 21/28, Loss:0.30985933542251587\n",
      "Iter: 22/28, Loss:0.36910930275917053\n",
      "Iter: 23/28, Loss:0.42789533734321594\n",
      "Iter: 24/28, Loss:0.44312265515327454\n",
      "Iter: 25/28, Loss:0.4323199391365051\n",
      "Iter: 26/28, Loss:0.4177170693874359\n",
      "Iter: 27/28, Loss:0.453907310962677\n",
      "Iter: 28/28, Loss:0.3758785128593445\n",
      "Epoch 37/100: Train loss = 0.41664090752601624, Val loss = 0.6168756484985352, Train acc = 0.8741589119541875, Val acc = 0.8093875214653692\n",
      "Better params found in epoch = 37, saved params\n",
      "Epoch nro 38/100\n",
      "Iter: 1/28, Loss:0.4178861379623413\n",
      "Iter: 2/28, Loss:0.38737115263938904\n",
      "Iter: 3/28, Loss:0.3759063482284546\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\EL7024\\audio_training.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/EL7024/audio_training.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/EL7024/audio_training.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/EL7024/audio_training.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train \u001b[39m=\u001b[39m audiotrain\u001b[39m.\u001b[39mtrain(model, \u001b[39m100\u001b[39m, train_dl, val_dl, criterion, optimizer, state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msilent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain_params\u001b[39m\u001b[39m\"\u001b[39m, device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\GitHub\\EL7024\\audio\\audio_model.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, train_dataset, val_dataset, criterion, optimizer, state, name, dir, device)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, epochs):\n\u001b[0;32m    181\u001b[0m     \u001b[39m# Train\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch nro \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 183\u001b[0m     t_loss, t_acc \u001b[39m=\u001b[39m train_epoch(model, train_dataset, criterion, optimizer, device)\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Validate\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     v_loss, v_acc \u001b[39m=\u001b[39m validate(model, val_dataset, criterion, device)\n",
      "File \u001b[1;32md:\\GitHub\\EL7024\\audio\\audio_model.py:114\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_dataset, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m    112\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    113\u001b[0m total_prediction \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m    115\u001b[0m     loss, y, y_pred \u001b[39m=\u001b[39m get_loss(model, batch, criterion, device)\n\u001b[0;32m    116\u001b[0m     \u001b[39m#\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\GitHub\\EL7024\\audio\\audio_data.py:143\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    140\u001b[0m         dur_aud \u001b[39m=\u001b[39m corrupt\u001b[39m.\u001b[39msilent_audio(dur_aud)\n\u001b[0;32m    141\u001b[0m \u001b[39m# shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m# augm_aud = corrupt.silent_audio(dur_aud)\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m sgram \u001b[39m=\u001b[39m AudioUtil\u001b[39m.\u001b[39mspectro_gram(dur_aud, n_mels\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, n_fft\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, hop_len\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    144\u001b[0m \u001b[39m# aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m sgram, class_id\n",
      "File \u001b[1;32md:\\GitHub\\EL7024\\audio\\audio_data.py:92\u001b[0m, in \u001b[0;36mAudioUtil.spectro_gram\u001b[1;34m(aud, n_mels, n_fft, hop_len)\u001b[0m\n\u001b[0;32m     89\u001b[0m top_db \u001b[39m=\u001b[39m \u001b[39m80\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[39m# spec has shape [channel, n_mels, time], where channel is mono, stereo etc\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m spec \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mMelSpectrogram(sr, n_fft\u001b[39m=\u001b[39mn_fft, hop_length\u001b[39m=\u001b[39mhop_len, n_mels\u001b[39m=\u001b[39mn_mels)(sig)\n\u001b[0;32m     94\u001b[0m \u001b[39m# Convert to decibels\u001b[39;00m\n\u001b[0;32m     95\u001b[0m spec \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mAmplitudeToDB(top_db\u001b[39m=\u001b[39mtop_db)(spec)\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torchaudio\\transforms\\_transforms.py:650\u001b[0m, in \u001b[0;36mMelSpectrogram.forward\u001b[1;34m(self, waveform)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveform: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    643\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[39m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     specgram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspectrogram(waveform)\n\u001b[0;32m    651\u001b[0m     mel_specgram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmel_scale(specgram)\n\u001b[0;32m    652\u001b[0m     \u001b[39mreturn\u001b[39;00m mel_specgram\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torchaudio\\transforms\\_transforms.py:110\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[1;34m(self, waveform)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveform: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    101\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mspectrogram(\n\u001b[0;32m    111\u001b[0m         waveform,\n\u001b[0;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad,\n\u001b[0;32m    113\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow,\n\u001b[0;32m    114\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_fft,\n\u001b[0;32m    115\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhop_length,\n\u001b[0;32m    116\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwin_length,\n\u001b[0;32m    117\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpower,\n\u001b[0;32m    118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalized,\n\u001b[0;32m    119\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcenter,\n\u001b[0;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_mode,\n\u001b[0;32m    121\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monesided,\n\u001b[0;32m    122\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torchaudio\\functional\\functional.py:126\u001b[0m, in \u001b[0;36mspectrogram\u001b[1;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[0m\n\u001b[0;32m    123\u001b[0m waveform \u001b[39m=\u001b[39m waveform\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m    125\u001b[0m \u001b[39m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m spec_f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstft(\n\u001b[0;32m    127\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mwaveform,\n\u001b[0;32m    128\u001b[0m     n_fft\u001b[39m=\u001b[39mn_fft,\n\u001b[0;32m    129\u001b[0m     hop_length\u001b[39m=\u001b[39mhop_length,\n\u001b[0;32m    130\u001b[0m     win_length\u001b[39m=\u001b[39mwin_length,\n\u001b[0;32m    131\u001b[0m     window\u001b[39m=\u001b[39mwindow,\n\u001b[0;32m    132\u001b[0m     center\u001b[39m=\u001b[39mcenter,\n\u001b[0;32m    133\u001b[0m     pad_mode\u001b[39m=\u001b[39mpad_mode,\n\u001b[0;32m    134\u001b[0m     normalized\u001b[39m=\u001b[39mframe_length_norm,\n\u001b[0;32m    135\u001b[0m     onesided\u001b[39m=\u001b[39monesided,\n\u001b[0;32m    136\u001b[0m     return_complex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    137\u001b[0m )\n\u001b[0;32m    139\u001b[0m \u001b[39m# unpack batch\u001b[39;00m\n\u001b[0;32m    140\u001b[0m spec_f \u001b[39m=\u001b[39m spec_f\u001b[39m.\u001b[39mreshape(shape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m spec_f\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:])\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\functional.py:639\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[0m\n\u001b[0;32m    637\u001b[0m     extended_shape \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m (\u001b[39m3\u001b[39m \u001b[39m-\u001b[39m signal_dim) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m    638\u001b[0m     pad \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m--> 639\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mview(extended_shape), [pad, pad], pad_mode)\n\u001b[0;32m    640\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mview(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39msignal_dim:])\n\u001b[0;32m    641\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mstft(\u001b[39minput\u001b[39m, n_fft, hop_length, win_length, window,  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    642\u001b[0m                 normalized, onesided, return_complex)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = audiotrain.AudioModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "train = audiotrain.train(model, 100, train_dl, val_dl, criterion, optimizer, state = \"train_params\\\\silent_37\", name = \"silent\", dir = \"train_params\", device = \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
