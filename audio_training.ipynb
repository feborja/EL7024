{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de audio con corrupciones\n",
    "Hecho por:\n",
    "* Ammi Beltrán\n",
    "* Fernanda Borja\n",
    "* Luciano Vidal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirección del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"D:\\\\OneDrive\\\\OneDrive - Universidad de Chile\\\\Semestre X\\\\Teoria de la informacion\\\\proyecto\\\\UrbanSound8K\\\\UrbanSound8K\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Locals\n",
    "import audio.audio_corrupts as corrupt\n",
    "import audio.audio_model as audiotrain\n",
    "import audio.audio_data as dataudio\n",
    "# Torch\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\audio\\fold5\\100032-3-0-0.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-117.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-121.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-126.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\audio\\fold5\\100263-2-0-137.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     relative_path  classID\n",
       "0    \\audio\\fold5\\100032-3-0-0.wav        3\n",
       "1  \\audio\\fold5\\100263-2-0-117.wav        2\n",
       "2  \\audio\\fold5\\100263-2-0-121.wav        2\n",
       "3  \\audio\\fold5\\100263-2-0-126.wav        2\n",
       "4  \\audio\\fold5\\100263-2-0-137.wav        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.path.join(DATA, \"metadata\", \"UrbanSound8K.csv\")\n",
    "df = pd.read_csv(file)\n",
    "df['relative_path'] = '\\\\audio' + '\\\\fold' + df['fold'].astype(str) + '\\\\' + df['slice_file_name'].astype(str)\n",
    "df = df[['relative_path', 'classID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "myds = dataudio.SoundDS(df, DATA)\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=250, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=250, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch nro 1/2\n",
      "Iter: 1/28, Loss:2.3870630264282227\n",
      "Iter: 2/28, Loss:2.3098506927490234\n",
      "Iter: 3/28, Loss:2.280787944793701\n",
      "Iter: 4/28, Loss:2.2225255966186523\n",
      "Iter: 5/28, Loss:2.2008330821990967\n",
      "Iter: 6/28, Loss:2.126309394836426\n",
      "Iter: 7/28, Loss:2.108445882797241\n",
      "Iter: 8/28, Loss:2.1314704418182373\n",
      "Iter: 9/28, Loss:2.0661816596984863\n",
      "Iter: 10/28, Loss:2.034797191619873\n",
      "Iter: 11/28, Loss:2.0374364852905273\n",
      "Iter: 12/28, Loss:1.9620651006698608\n",
      "Iter: 13/28, Loss:2.031630754470825\n",
      "Iter: 14/28, Loss:1.982208490371704\n",
      "Iter: 15/28, Loss:1.92704176902771\n",
      "Iter: 16/28, Loss:1.9501131772994995\n",
      "Iter: 17/28, Loss:1.9157882928848267\n",
      "Iter: 18/28, Loss:1.9641270637512207\n",
      "Iter: 19/28, Loss:1.888587236404419\n",
      "Iter: 20/28, Loss:1.9353240728378296\n",
      "Iter: 21/28, Loss:1.8919373750686646\n",
      "Iter: 22/28, Loss:1.8880292177200317\n",
      "Iter: 23/28, Loss:1.8455307483673096\n",
      "Iter: 24/28, Loss:1.8752615451812744\n",
      "Iter: 25/28, Loss:1.8659809827804565\n",
      "Iter: 26/28, Loss:1.8600471019744873\n",
      "Iter: 27/28, Loss:1.8268464803695679\n",
      "Iter: 28/28, Loss:1.8235512971878052\n",
      "Epoch 1/2: Train loss = 2.0121350288391113, Val loss = 1.7819520235061646, Train acc = 0.2917263097623819, Val acc = 0.4261168384879725\n",
      "Better params found in epoch = 1, saved params\n",
      "Epoch nro 2/2\n",
      "Iter: 1/28, Loss:1.7884814739227295\n",
      "Iter: 2/28, Loss:1.7513352632522583\n",
      "Iter: 3/28, Loss:1.7664868831634521\n",
      "Iter: 4/28, Loss:1.715750813484192\n",
      "Iter: 5/28, Loss:1.7772024869918823\n",
      "Iter: 6/28, Loss:1.7792627811431885\n",
      "Iter: 7/28, Loss:1.7472689151763916\n",
      "Iter: 8/28, Loss:1.6750253438949585\n",
      "Iter: 9/28, Loss:1.7056217193603516\n",
      "Iter: 10/28, Loss:1.6350492238998413\n",
      "Iter: 11/28, Loss:1.7094802856445312\n",
      "Iter: 12/28, Loss:1.6640650033950806\n",
      "Iter: 13/28, Loss:1.6615153551101685\n",
      "Iter: 14/28, Loss:1.6897112131118774\n",
      "Iter: 15/28, Loss:1.7270832061767578\n",
      "Iter: 16/28, Loss:1.691345453262329\n",
      "Iter: 17/28, Loss:1.6346770524978638\n",
      "Iter: 18/28, Loss:1.5732512474060059\n",
      "Iter: 19/28, Loss:1.5830415487289429\n",
      "Iter: 20/28, Loss:1.579211950302124\n",
      "Iter: 21/28, Loss:1.6392064094543457\n",
      "Iter: 22/28, Loss:1.5867992639541626\n",
      "Iter: 23/28, Loss:1.6014976501464844\n",
      "Iter: 24/28, Loss:1.558635950088501\n",
      "Iter: 25/28, Loss:1.6248465776443481\n",
      "Iter: 26/28, Loss:1.6265513896942139\n",
      "Iter: 27/28, Loss:1.5736414194107056\n",
      "Iter: 28/28, Loss:1.5028505325317383\n",
      "Epoch 2/2: Train loss = 1.6631749868392944, Val loss = 1.522692322731018, Train acc = 0.4596335528199256, Val acc = 0.5137457044673539\n",
      "Better params found in epoch = 2, saved params\n",
      "Se ha guardado la época múltiplo de 2\n"
     ]
    }
   ],
   "source": [
    "model = audiotrain.AudioModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "train = audiotrain.train(model, 2, train_dl, val_dl, criterion, optimizer, state = None, name = \"clean\", dir = \"train_params\", device = \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
