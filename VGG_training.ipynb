{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIpxwbcpdAA6"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8PiIyxuKdAA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "#\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv4dyfXafotX",
        "outputId": "cbd2a67c-0089-432d-bd1b-25b951b7a6ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE_PATH = \"\" #Local\n",
        "SAVE_PATH = \"/content/gdrive/MyDrive/VGG\""
      ],
      "metadata": {
        "id": "kpXEtPHhVeLD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byjMropLU87w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdAZX-QhdAA9"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSWUWq4kdAA9"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hbFfXzXdAA9"
      },
      "outputs": [],
      "source": [
        "class EncoderVGG16(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_layers = 5,\n",
        "                 h_dims = [512,256,128,10]):\n",
        "        super(EncoderVGG16,self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.h_dims = h_dims\n",
        "        self.layers = [4,9,16,23,31]\n",
        "        self.full_vgg16 = torchvision.models.vgg16()\n",
        "        self.vgg = self.full_vgg16.features[:self.layers[self.n_layers-1]]\n",
        "        self.classifier = self.full_vgg16.classifier\n",
        "\n",
        "        self.classifier[0] = nn.Linear(self.h_dims[0], self.h_dims[1])\n",
        "        self.classifier[3] = nn.Linear(self.h_dims[1], self.h_dims[2])\n",
        "        self.classifier[6] = nn.Linear(self.h_dims[2], self.h_dims[3])\n",
        "\n",
        "    def encode(self,x):\n",
        "        return self.vgg(x)\n",
        "\n",
        "    def forward(self,x):\n",
        "        latent = self.encode(x)\n",
        "        latent = torch.flatten(latent,start_dim = 1)\n",
        "        output = self.classifier(latent)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKHJMvqXdAA-"
      },
      "outputs": [],
      "source": [
        "model = EncoderVGG16()\n",
        "# model.vgg, model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5PJHDCmdAA-",
        "outputId": "72ad037e-489f-468e-ef61-cb13c20e4464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderVGG16(\n",
              "  (full_vgg16): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=128, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (vgg): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "043fLq42dAA-"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVMGfi5adAA_"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "    print(\"Data directory created :D\")\n",
        "\n",
        "if not os.path.exists(\"data/train\"):\n",
        "    os.makedirs(\"data/train\")\n",
        "    print(\"Data train directory created :D\")\n",
        "\n",
        "if not os.path.exists(\"data/val\"):\n",
        "    os.makedirs(\"data/val\")\n",
        "    print(\"Data val directory created :D\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_save = os.path.join(SAVE_PATH,\"clean_params\")\n",
        "# if not os.path.exists(final_save):\n",
        "#     os.makedirs(final_save)\n",
        "#     print(\"Data directory created :D\")\n"
      ],
      "metadata": {
        "id": "iPBZ-0MjVv4o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d9qEGk0dAA_"
      },
      "outputs": [],
      "source": [
        "# from corrupter import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUA4WbP0dAA_"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "     # transforms.Resize(size=(224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    #  transforms.Lambda(gaussian_pixels)\n",
        "     ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2OYtsczdAA_",
        "outputId": "822c53fa-a6c6-46f6-e673-1306e627cab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root = \"data/train/\",train=True, transform= transform,download=True)\n",
        "val_dataset = torchvision.datasets.CIFAR10(root = \"data/val/\",train = False, transform= transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "bCRFVf5zdAA_",
        "outputId": "ed2ad4cd-1edb-454e-c120-070939769891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAKXUlEQVR4nAXBf3Ac1X0A8Mfj68fz83q9Wq1W5/XqdByXs3wS6mFsYYxjG2IbO9jJUAotPxqTMmRCaSZJm0zCpC1DCf+kza9JS9rMBDKTH5MfhITCAHWAJKQIWRhbUYQsy/L5dD6v1+v1er1+en48v7zk87nqC//yeLu9YIP+gGW2rPUaNX9tZbVFGLVdROhCq70kzbWVMihRFEWe547rKKTOZ/FAJURG8YITxAghQank9/mMOVnBDQYElF/i0uCrrl23rj03V3PQbXXnjmawfdvIKhv+pIzBVprzNCuE0pRghxopNQFq23aaJ1LzoaE6ECSKooc6lwqulOz1fAwME4YAzudCCkGoDS7FyEZb686to+WR4VqP5wPGF4o8EoXB2HJdJI3RxUDNe1+YFcy9opCw7ILnQuJllt3ju45lE5wYo99HeBlGJb8vTs4JKQCjqNsBB8sgoPvGqnWXMJ2fXeBKQ/uchJUorJSoZbc7EaWoFng93eRKnmS5EAiXfF/wDBRltq2UuIZgXYhlzAIti/gEUsYmSGrdOVtA1aaubZf73UbIlFYKIUIJAii0oJReY/QfiswQeG+mrYSK0nRO8ZIbpoXSSAM2xO7JkgseG+gz5krOLwipkWnH+UvnRJzKXAAMV5yAEcchVxPT77pCKo3wecO5NIqLJSMWFDfUiniiFEmVlu/r6KyYPJ4w0L+NsZg6mi2mW9btGR65GQcd0zoWx0nndD7XyX493lGEwoZhP7RkybOwEQgZbPSlLDUI14Nyn++c7syVwzDKxZsH5+KCWBqNeZSy7Dfz7YuGMGwGw+Cf7n7k9GFlUlMeYj0pPRqDzdjmZjAyMjrdzaEWuJS3VzLq2V6RictaDlaqxphrFAiR95ZK784WB37beS+SqUTbXPLslz6+aX3pi9/51ddemZKaUzBn2u8lZwoZMKSw4zDLIR5mUsktt2wIFiIYrq3NFnKKaZyKC1xSTJYLBQhdEHywGnJlXnv70PGuMtQiBEJHLaOnnYWLe+ZveKoG0+2ZIuXPvPgSSH2wP7ypPIqADpS9P2qTc2F4d1vDh+pQo1pyAVi726LJGVDqj0hjRvtLjkE9v/jViweLxHHsHou6vlcl8slXpyWnRbnZuM7BKBQyT3mWpIZfllhwhBEDbICsplQWBVMGEDDMGELIdlgv6qcIAGAl0rZbPjYVPT/X2llzihw5vrfv9jEocpewbrdFSWe15VvV23ft2fLGW//1wouT1vLCmFhKCtRiFtNaa4QxBshygUWGkEySU0sCJPScTU9302jjZmrk6a1DeOdGluZ4bO/+7SZvdYRbWYvmyebmje0k2fHRD4d7vfBv7xp9LGotdpjlg7GFVlojJSRgZIwBhZVR0hjjOr2lwHt3Nnv57VnKzNHpd+Z/P7vnevb04x8+8M5CsLExVG/OzE5XKj5oZgGZmZ2k5fZs+/DkkXj5S97SgM4yYyhgwForwBgDKIOgMliSZ2Uc50aoTrT45u+m4zh2HTj8enfUscbGtlY2fIit0ajBNn3sUWdq0pWzCl1Mkny91+BKY7+06c4NweHmnuNTzvQxgVdc5BeXg/Fth2cxsxhEi/M0jRgGRBAlJI071cCv9DvZie7wxvq/3v/4jyV/6f/45x6rtdt8dNfHAKW8uLdidHdm3uVifa3WVjZ7oJp96/BXPvXwxPh7yywGCGcGCQQgBBCMVHbGIAxIKkxOCNTtGlPw9YP+3z/x5Kb7Pv3Atg82aYnwbPK1A80df+XUd/smShdmXF3lWToXpZXGbfXm9iwOYQ268kqOAWvBsVTYKC0pYIOUEBiAAjKZuFqjWt1r9smHPrnvi32fbs1ktlzccdPNuqmbIw2Zy7TNuZQiowqVDkxO/OjH//O5zzxab9a70Qzz+tdu9/XVoJaULPip2XYReaClygpt+SVKVxC4tPuGquPCtq23fPkLT6z/529872vbtjz5XPOee63GLuqNpnmcdaPpQ+Ot6QklUjdwhobY+KFnR9d/W6axyQqctJTJTGFcm61rsq6NgRF6MkpVjl3PJWBk3Rt/t73roa9v+sZ/IlQVUVJeXW784MGE1n76zNNFlnS7i3PvfICouxyHjt069sDeD0riM3IfswS9eCH95aSWSgI6S0hv3R+9sQ5Flns2vcohDKRRkpTI7ue/++UfvB4OjU6/9jyBne0zndnH/vdQpJ74+IP9LrtYPPYXohwG/W9MvMV/J2ufxXvv+wRS9kJ7Is2vPplJbGie6dgYE+d3XkKgDUdaYamlERgbxw4f/MTDNvu75773TOvQgaLYGLWOj7/689i4y9W/1ykJHb9x7eDh+SOyK9IoHn/jLYT2x3HkUCPt++dl6LqOF7gutaO0K7UEhLSWfAXzlFRLSN5Svu4fH95Yu/62kfX/xtMOY3bJH6BAfMaaI2uz6IRL7PmjR0WuAsfl8ZmXn/32YffuQmaIEZV0/E0+8jnY+SotXeTec/eHQGu8ghKHagR4gPgBF3NzR+KfHHH3/UwjUqv6lXsb0i0mD00ZZAAol5Jg5jue1IhIjbBRfBE07qYnluwMbyiSnnak+eI52Llmx9CDdQBsO7ZrkPRdzw/WpSKvBxZFkp+a1mCl1+nR0Vs15x95wP0P+iVuzjGMszgNg9Ciywm+Euf5rw+32idlgZOFfbBx0D1tWa1jqZUxP6hnqcIWBV4U2lia2Kk4T8gVz+n1g2Grtzw6PBSdnE25aGzenWr7nkc+/5f7HwHacy4u0jTDGGOkj0we+v/Xp+I0c1d7jdoIzhk+4ldnhu5wbttUufnV56ZgdB2IF+YzpZMEGVCU0jBcazGWneu6gxRx+t9f/eqOfbsmDk4BYG9lhxC7x/VFnGVZJiUvufaqh/Y6wYAkl5VIl97OYcoZ9oJ/uOOvR0ZGv3Pkddiy2Srf6bz6djo9a5aU3V+iSbqo9BmCYOGVY9Gb8qLokBcWA3Td9NTxiZ/negaPNtZiLVrtE7ZvV8qBRZYV/H1EVyRFzmPWp+EjN9+w4ZP18Ynp47MphFWWzabVEYJ8r2e6uMx5vxVyjrRQQhWnslafa+dpnuVHuVBXhDKGrO6eC8PeMCxnWTo33yqVfAyApbGoazvIssj23duz1Dz11M+e/uEMUIc6oVW7EWhWsON6sEWpAte5XjGtipOWRxm1CPEKo7ngxmBsUB/PVY4YXYEse7HVAi4GKiEFALryPJJ/mIu+Hsso6cy0fzmdIohjhkip5OfMNf6NTjnR8eks7v4+TpXI1Wqr7jMmi4JSsAD12qQXg1eiQJFUly13+ZqKd2IhiowOa/VUXnr5N/OP/3D8+e+Hozf1+WU9VA5g4k1ULDrBOum4olxCtRqNt6Xtdto6brXmEdFEG6OUQloBQhgwoTRTYCRiWsh0QWWpomwxTj2FFrrZ91+Zb88nPFHNcvOurWPdDIFiQ2LFI0VQgJxzyrjScKoga6lu3+u250iWUCUt9CfQUudZblkWoSTKdRbnzPAA1mg4JQS1fbOKrTpvXdqJKvfv95+6f//2v7n90c9+8+Ch+M/Nz9NlOZ7KjwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_image_zero, train_target_zero =train_dataset[0]\n",
        "transforms.ToPILImage()(train_image_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIBQmfY7dABA",
        "outputId": "21040d3a-56f9-4119-e32b-13b646edd9fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: data/train/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVLaZW79dABA",
        "outputId": "27e8d682-0b0e-4f25-d329-28d5e40aef46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data/val/\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFj7q6PNdABA"
      },
      "source": [
        "# DataLoaders y criterios de optimización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxW9uS91dABA"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(train_dataset, batch_size=1000,shuffle=True,)\n",
        "valloader = DataLoader(val_dataset,batch_size= 1000,shuffle= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQIy7eXudABA"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.005, weight_decay= 1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYhnl38kdABB"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLLlb6gKdABB"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, cuda):\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Batch {i}/{len(train_loader)}\")\n",
        "\n",
        "        inputs, labels = data\n",
        "\n",
        "        if cuda:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    accuracy = correct/total\n",
        "    train_loss /= len(train_loader)\n",
        "    return train_loss, accuracy\n",
        "\n",
        "def validate(model, val_loader, criterion, cuda):\n",
        "\n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "\n",
        "            inputs, labels = data\n",
        "\n",
        "            if cuda:\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs,labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    accuracy = correct/total\n",
        "    return val_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mehZZSmhdABB"
      },
      "outputs": [],
      "source": [
        "def training(model,\n",
        "             epochs,\n",
        "             train_loader,\n",
        "             val_loader,\n",
        "             criterion,\n",
        "             optimizer,\n",
        "             each = 50,\n",
        "             state = None,\n",
        "             name = \"\",\n",
        "             cuda = True):\n",
        "\n",
        "    # If trained before\n",
        "    if state == None:\n",
        "        state = {\n",
        "            \"epoch\" : 0,\n",
        "            \"loss\" : [[], []], # [train, val]\n",
        "            \"acc\" : [[], []], # [train, val]\n",
        "            \"params\" : None,\n",
        "            \"bestloss\" : np.inf\n",
        "        }\n",
        "\n",
        "    # If previously trained\n",
        "    else:\n",
        "        state = torch.load(state)\n",
        "        model.load_state_dict(state[\"params\"])\n",
        "\n",
        "    best_loss = state[\"bestloss\"]\n",
        "    state_epochs = state[\"epoch\"]\n",
        "\n",
        "    if cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    for epoch in range(state_epochs, state_epochs + epochs):\n",
        "        print(f\"Epoch nro {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, cuda)\n",
        "        # Val\n",
        "        val_loss, val_acc = validate(model, val_loader,criterion, cuda)\n",
        "\n",
        "        print(f\"Train loss = {train_loss}, Val loss = {val_loss}\")\n",
        "        print(f\"Train acc = {train_acc}, Val acc = {val_acc}\")\n",
        "        # print(f\"Val acc = {val_acc}\")\n",
        "\n",
        "        if (best_loss > val_loss):\n",
        "            best_loss = val_loss\n",
        "            print(f\"Better params found in epoch = {epoch + 1}, saved params\")\n",
        "            torch.save(model.state_dict(), os.path.join(final_save,f'bestVGGParams{name}.pt'))\n",
        "        # Load best model so far to proceed\n",
        "\n",
        "        # Save periodically for each\n",
        "        if ((epoch + 1)%each == 0):\n",
        "            print(f\"Se ha guardado la época múltiplo de {each}\")\n",
        "            torch.save(model.state_dict(), os.path.join(final_save,f'eachVGGParams_{epoch + 1}.pt'))\n",
        "\n",
        "        # Update state\n",
        "        state[\"loss\"][0].append(train_loss)\n",
        "        state[\"loss\"][1].append(val_loss)\n",
        "        state[\"acc\"][0].append(train_acc)\n",
        "        state[\"acc\"][1].append(val_acc)\n",
        "        state[\"epoch\"] = epoch + 1\n",
        "        state[\"params\"] = model.state_dict()\n",
        "        state[\"bestloss\"] = best_loss\n",
        "\n",
        "        # Save per epoch just in case\n",
        "        torch.save(state, os.path.join(final_save,f\"VGG_{epoch + 1}.pt\"))\n",
        "    return state[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dir = os.path.join(final_save,f\"VGG_{<LAST>}\")"
      ],
      "metadata": {
        "id": "cjXQ77YaX67U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "--KVk1lidABB",
        "outputId": "e7428620-4744-4415-c886-582fdc837486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch nro 1/100\n",
            "Batch 0/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-52159ea265e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_state = training(model = model,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-aa33b4c9b6b7>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, epochs, train_loader, val_loader, criterion, optimizer, each, state, name, cuda)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-71f7ced31c89>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, cuda)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_state = training(model = model,\n",
        "                     epochs = 100,\n",
        "                     train_loader = trainloader,\n",
        "                     val_loader = valloader,\n",
        "                     criterion = criterion,\n",
        "                     optimizer = optimizer,\n",
        "                     each = 2,\n",
        "                     state = None, #If trained state_dir\n",
        "                     name = \"Clean\",\n",
        "                     cuda = True,)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}